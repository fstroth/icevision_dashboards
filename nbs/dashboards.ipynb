{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dashboards\n",
    "> Supplies dashboards to investigate datasets and training results. Dashboards are defined as classes, to show the dashboard use the .show() function on an dashboard instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Union, Optional, List\n",
    "from abc import abstractmethod, ABC\n",
    "from math import ceil, floor\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bokeh.plotting import show, output_notebook, gridplot, figure\n",
    "from bokeh.models.widgets import DataTable, TableColumn, HTMLTemplateFormatter\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Title\n",
    "from bokeh import events\n",
    "\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from icevision_dashboards.core.dashboards import *\n",
    "from icevision_dashboards.plotting import *\n",
    "from icevision_dashboards.core.data import *\n",
    "from icevision_dashboards.data import *\n",
    "from icevision_dashboards.plotting.utils import toggle_legend_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = icedata.fridge.load_data()\n",
    "test_class_map = icedata.fridge.class_map()\n",
    "test_parser = icedata.fridge.parser(test_data_dir)\n",
    "test_train_records, test_valid_records = test_parser.parse()\n",
    "test_valid_record_dataset = BboxRecordDataset(test_valid_records, test_class_map)\n",
    "test_train_record_dataset = BboxRecordDataset(test_train_records, test_class_map)\n",
    "test_very_large_record_dataset = BboxRecordDataset(test_valid_records*10, test_class_map)\n",
    "test_record_dataset_no_class_map = BboxRecordDataset(test_train_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_record_list = [copy.deepcopy(test_valid_records[0]) for i in range(40_000)]\n",
    "for index, record in enumerate(long_record_list):\n",
    "    record.imageid = index\n",
    "    record.filepath = Path(str(\"imgs/\"+str(index)+\".jpg\"))\n",
    "    record.width = np.random.randint(1, 10_000)\n",
    "long_record_dataset = BboxRecordDataset(long_record_list, test_class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionDatasetOverview(DatasetOverview):\n",
    "    \"\"\"Dataset overview for object detection datasets\"\"\"\n",
    "    DESCRIPTOR_DATA = \"data\"\n",
    "    DESCRIPTOR_STATS_DATASET = \"stats_dataset\"\n",
    "    DESCRIPTOR_STATS_IMAGES = \"stats_image\"\n",
    "    DESCRIPTOR_STATS_ANNOTATIONS = \"stats_class\"\n",
    "    \n",
    "    # change these \n",
    "    IMAGE_IDENTIFIER_COL = \"filepath\"\n",
    "    ANNOTATON_LABEL_COL = \"label\"\n",
    "    OBJECTS_PER_IMAGE_COL = \"num_annotations\"\n",
    "    AREA_COL = \"area\"\n",
    "    \n",
    "    def _generate_datset_stats_tab(self):\n",
    "        dataset_overview_table = table_from_dataframe(getattr(self.dataset, self.DESCRIPTOR_STATS_DATASET), width=self.width, height=self.height//7)\n",
    "        images_overview_table = table_from_dataframe(getattr(self.dataset, self.DESCRIPTOR_STATS_IMAGES), width=self.width, height=self.height//7)\n",
    "        classes_overview_table = table_from_dataframe(getattr(self.dataset, self.DESCRIPTOR_STATS_ANNOTATIONS), width=self.width, height=self.height//4)\n",
    "        \n",
    "        class_occurances = self.dataset.data.groupby(\"label\").count()[\"id\"]\n",
    "        class_occurance_barplot = barplot(counts=class_occurances.values, values=np.array(class_occurances.index), bar_type=\"vertical\", height=(self.height//5)*2)\n",
    "\n",
    "        return pn.Column(\"<b>Dataset stats</b>\", dataset_overview_table, \"<b>Image stats</b>\", images_overview_table, \"<b>Class stats</b>\", classes_overview_table, pn.Row(class_occurance_barplot, align=\"center\"))\n",
    "    \n",
    "    def _generate_annotations_tab(self):\n",
    "        plot_size = floor(min(self.height, self.width)*0.45)\n",
    "        # mixing of classes\n",
    "        mixing_matrix_classes_in_images = utils.calculate_mixing_matrix(getattr(self.dataset, self.DESCRIPTOR_DATA), self.IMAGE_IDENTIFIER_COL, self.ANNOTATON_LABEL_COL)\n",
    "        self.class_mixing_matrix_plot = pn.Column(\"<b>Class mixing</b>\", heatmap(mixing_matrix_classes_in_images, \"row_name\", \"col_name\", \"values\", width=plot_size, height=plot_size), height=self.height)\n",
    "        # number of object per image, stacked hist\n",
    "        self.classes_for_objects_per_image_stacked_hist = pn.Column(\n",
    "            \"<b>Objects per Image</b>\", \n",
    "            stacked_hist(getattr(self.dataset, self.DESCRIPTOR_DATA), self.OBJECTS_PER_IMAGE_COL, self.ANNOTATON_LABEL_COL, \"Objects per Image\", width=plot_size, height=plot_size)\n",
    "        )\n",
    "        # categorical overview\n",
    "        self.categorical_2d_histogram = categorical_2d_histogram_with_gui(\n",
    "            getattr(self.dataset, self.DESCRIPTOR_DATA),\n",
    "            category_cols=[\"label\", \"num_annotations\", \"width\", \"height\"],\n",
    "            hist_cols=[\"num_annotations\", \"area\", \"area_normalized\", \"area_square_root\", \"area_square_root_normalized\", \"bbox_ratio\", \"bbox_xmin\", \"bbox_xmax\", \"bbox_ymin\", \"bbox_ymax\", \"width\", \"height\"],\n",
    "            height=self.height//2, width=self.width//2\n",
    "        )\n",
    "        # ratio distribution\n",
    "        grid =  pn.GridSpec(ncols=2,nrows=2, width=self.width, height=self.height, align=\"center\")\n",
    "        grid[0,0] = self.class_mixing_matrix_plot\n",
    "        grid[1,0] = self.classes_for_objects_per_image_stacked_hist\n",
    "        grid[:,1] = pn.Column(self.categorical_2d_histogram, align=\"center\")\n",
    "        return grid \n",
    "    \n",
    "    def _generate_gallery_tab(self):\n",
    "        return pn.Column(Gallery(self.dataset, \"data\", \"filepath\", [\"num_annotations\", \"width\", \"height\", \"label\", \"area\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\"], height=self.height).show(), align=\"center\", sizing_mode=\"stretch_both\")\n",
    "    \n",
    "    def build_gui(self):\n",
    "        dataset_tab = super()._generate_dataset_tab()\n",
    "        dataset_stats_tab = self._generate_datset_stats_tab()\n",
    "        annotations_tab = self._generate_annotations_tab()\n",
    "        gallery_tab = self._generate_gallery_tab()\n",
    "        self.gui = pn.Tabs((\"Dataset stats\", dataset_stats_tab), (\"Annotations\", annotations_tab), (\"Gallery\", gallery_tab), (\"Dataset\", dataset_tab), align=\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_overview = ObjectDetectionDatasetOverview(test_valid_record_dataset, width=1500, height=900)\n",
    "test_object_detection_overview.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionDatasetComparison(DatasetComparison):\n",
    "    \"\"\"Dataset comparison for object detection datasets.\"\"\"\n",
    "    DESCRIPTOR_DATA = \"data\"\n",
    "    DESCRIPTOR_STATS_DATASET = \"stats_dataset\"\n",
    "    DESCRIPTOR_STATS_IMAGES = \"stats_image\"\n",
    "    DESCRIPTOR_STATS_ANNOTATIONS = \"stats_class\"\n",
    "    \n",
    "    # change these \n",
    "    IMAGE_IDENTIFIER_COL = \"filepath\"\n",
    "    ANNOTATON_LABEL_COL = \"label\"\n",
    "    OBJECTS_PER_IMAGE_COL = \"num_annotations\"\n",
    "    AREA_COL = \"area\"\n",
    "    \n",
    "    def _generate_dataset_tab(self):\n",
    "        overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA), width=floor(self.width/2), height=self.height)\n",
    "        return pn.Row(*overview_table)\n",
    "    \n",
    "    def _generate_datset_stats_tab(self):\n",
    "        dataset_overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_STATS_DATASET), width=floor(self.width/2), height=self.height//7)\n",
    "        images_overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_STATS_IMAGES), width=floor(self.width/2), height=self.height//7)\n",
    "        classes_overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_STATS_ANNOTATIONS), width=floor(self.width/2), height=self.height//4)\n",
    "        \n",
    "        class_occurances_values = [dataset.data.groupby(\"label\").count()[\"id\"].values for dataset in self.datasets]\n",
    "        class_occurances_index = [np.array(dataset.data.groupby(\"label\").count()[\"id\"].index) for dataset in self.datasets]\n",
    "        class_occurance_barplot = barplot(counts=class_occurances_values, values=class_occurances_index, bar_type=\"vertical\", height=(self.height//5)*2, width=floor(self.width/2))\n",
    "\n",
    "        dublication_data = {dataset.name if dataset.name is not None else \"Dataset_\"+str(index): [getattr(dataset, self.DESCRIPTOR_DATA).duplicated().sum()] for index, dataset in enumerate(self.datasets)}\n",
    "        dublication_data[\"All\"] = pd.concat(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA)).duplicated().sum()\n",
    "        dublication_df = pd.DataFrame(dublication_data)\n",
    "        dublication_overview = table_from_dataframe(dublication_df)\n",
    "        \n",
    "        return pn.Column(\n",
    "            \"<b>Dublications</p>\", pn.Row(dublication_overview), \n",
    "            \"<b>Dataset stats</b>\", pn.Row(*dataset_overview_table), \n",
    "            \"<b>Image stats</b>\", pn.Row(*images_overview_table), \n",
    "            \"<b>Class stats</b>\", pn.Row(*classes_overview_table), \n",
    "            pn.Row(*class_occurance_barplot, align=\"center\")\n",
    "        )\n",
    "    \n",
    "    def _generate_annotations_tab(self):\n",
    "        plot_size = min(floor(self.width/len(self.datasets)), floor(self.height/2))\n",
    "        link_plots_checkbox = pnw.Checkbox(name=\"Link plot axis\", value=False)\n",
    "        \n",
    "        @pn.depends(link_plots_checkbox.param.value)\n",
    "        def _mixing_plots(link_plots):\n",
    "            # mixing of classes\n",
    "            mixing_matrix_classes_in_images = [utils.calculate_mixing_matrix(dataset, self.IMAGE_IDENTIFIER_COL, self.ANNOTATON_LABEL_COL) for dataset in self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA)]\n",
    "            class_mixing_matrix_plot = pn.Row(\"<b>Class mixing</b>\", *heatmap(mixing_matrix_classes_in_images, \"row_name\", \"col_name\", \"values\", link_plots=link_plots, width=plot_size, height=plot_size))\n",
    "            # number of object per image, stacked hist\n",
    "            classes_for_objects_per_image_stacked_hist = pn.Row(\n",
    "                \"<b>Objects per Image</b>\", \n",
    "                *stacked_hist(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA), self.OBJECTS_PER_IMAGE_COL, self.ANNOTATON_LABEL_COL, \"Objects per Image\", link_plots=link_plots, width=plot_size, height=plot_size)\n",
    "            )\n",
    "            return pn.Column(link_plots_checkbox, class_mixing_matrix_plot, classes_for_objects_per_image_stacked_hist)\n",
    "            \n",
    "        # categorical overview\n",
    "        self.categorical_2d_histogram = categorical_2d_histogram_with_gui(\n",
    "            self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA),\n",
    "            category_cols=[\"label\", \"num_annotations\", \"width\", \"height\"],\n",
    "            hist_cols=[\"num_annotations\", \"area\", \"area_normalized\", \"area_square_root\", \"area_square_root_normalized\", \"bbox_ratio\", \"bbox_xmin\", \"bbox_xmax\", \"bbox_ymin\", \"bbox_ymax\", \"bbox_width\", \"bbox_height\", \"width\", \"height\"],\n",
    "            height=floor(plot_size*1.5), width=floor(plot_size*1.5)\n",
    "        )\n",
    "        return pn.Column(_mixing_plots, self.categorical_2d_histogram, align=\"center\")\n",
    "    \n",
    "    def _generate_gallery_tab(self):\n",
    "        return pn.Row(*[Gallery(dataset, \"data\", \"filepath\", [\"num_annotations\", \"width\", \"height\", \"label\", \"area\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\"], width=floor(self.width/len(self.datasets))).show() for dataset in self.datasets], align=\"start\", sizing_mode=\"stretch_both\")\n",
    "    \n",
    "    def build_gui(self):\n",
    "        dataset_tab = self._generate_dataset_tab()\n",
    "        dataset_stats_tab = self._generate_datset_stats_tab()\n",
    "        annotations_tab = self._generate_annotations_tab()\n",
    "        gallery_tab = self._generate_gallery_tab()\n",
    "        self.gui = pn.Tabs((\"Dataset stats overview\", dataset_stats_tab), (\"Annotations overivew\", annotations_tab), (\"Gallery\", gallery_tab), (\"Dataset overview\", dataset_tab), align=\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_comparison = ObjectDetectionDatasetComparison([test_valid_record_dataset, test_train_record_dataset], width=1700, height=700)\n",
    "test_object_detection_comparison.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionDatasetGeneratorScatter(DatasetGeneratorScatter):\n",
    "    \"\"\"Dataset generator for object detection\"\"\"\n",
    "    DESCRIPTOR_STATS = \"stats_dataset\"\n",
    "    DATASET_OVERVIEW = ObjectDetectionDatasetOverview\n",
    "    DATASET_FILTER_COLUMNS = [\"width\", \"height\", \"label\", \"area_normalized\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"num_annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_generator = ObjectDetectionDatasetGeneratorScatter(test_valid_record_dataset, height=700, width=1000)\n",
    "test_dataset_generator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionDatasetGeneratorRange(DatasetGenerator):\n",
    "    \"\"\"Dataset generator for object detection\"\"\"\n",
    "    DESCRIPTOR_STATS = \"stats_dataset\"\n",
    "    DATASET_OVERVIEW = ObjectDetectionDatasetOverview\n",
    "    DATASET_FILTER_COLUMNS = [\"width\", \"height\", \"label\", \"area_normalized\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"num_annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_generator = ObjectDetectionDatasetGeneratorRange(test_valid_record_dataset, height=700, width=1000)\n",
    "test_dataset_generator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionResultOverview(Dashboard):\n",
    "    \"\"\"Overview dashboard \"\"\"\n",
    "    def __init__(self, dataset, plotting_backend=\"matplotlib\", height=700, width=1000):\n",
    "        self.dataset= dataset\n",
    "        self.plotting_backend = plotting_backend\n",
    "        super().__init__(width=width, height=height)\n",
    "        \n",
    "    def build_gui(self):\n",
    "        self.loss_tab = self.build_loss_tab()\n",
    "        self.ap_tab = self.build_precision_recall_tab()\n",
    "        self.gui = pn.Tabs((\"Loss\", self.loss_tab), (\"Precision-Recall\", self.ap_tab))\n",
    "    \n",
    "    def show(self):\n",
    "        return self.gui\n",
    "    \n",
    "    def show_loss_tab(self):\n",
    "        return self.loss_tab\n",
    "    \n",
    "    def show_ap_tab(self):\n",
    "        return self.ap_tab\n",
    "    \n",
    "    def build_loss_tab(self):\n",
    "        # loss hists\n",
    "        if self.plotting_backend == \"bokeh\":\n",
    "            bins_input = pnw.IntInput(name=\"Bins\", start=1, end=100, value=10)\n",
    "\n",
    "            @pn.depends(bins_input.param.value)\n",
    "            def loss_hists(bins):\n",
    "                unique_losses = self.dataset.base_data[[\"filepath\", \"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\", \"loss_total\"]].drop_duplicates()\n",
    "                hist_line = plots_as_matrix(\n",
    "                    histogram(\n",
    "                        [unique_losses[loss] for loss in [\"loss_total\", \"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\"]],\n",
    "                        title=[\"loss_total\", \"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\"], \n",
    "                        bins=bins, linked_axis=False), 5, 1, width=self.width, height=200\n",
    "                )\n",
    "                return hist_line\n",
    "            loss_hists_col = pn.Column(bins_input, loss_hists)\n",
    "        if self.plotting_backend == \"matplotlib\":\n",
    "            fig_loss_hists, ax_loss_hists = plt.subplots(1, 5, figsize=(16*5,9))\n",
    "            unique_losses = self.dataset.base_data[[\"filepath\", \"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\", \"loss_total\"]].drop_duplicates()\n",
    "            for single_ax, key in zip(ax_loss_hists, [\"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\", \"loss_total\"]):\n",
    "                single_ax.hist(unique_losses[key].values, bins=20)\n",
    "                single_ax.set_title(\" \".join(key.split(\"_\")).title(), fontsize=40)\n",
    "                for tick in single_ax.xaxis.get_major_ticks():\n",
    "                    tick.label.set_fontsize(34)\n",
    "                    tick.label.set_rotation(45)\n",
    "                for tick in single_ax.yaxis.get_major_ticks():\n",
    "                    tick.label.set_fontsize(34)\n",
    "            plt.close()\n",
    "            loss_hists_col = pn.pane.Matplotlib(fig_loss_hists, width=self.width)\n",
    "        axis_cols = ['score', 'area_normalized', 'area', 'bbox_ratio', 'bbox_width', 'bbox_height', 'num_annotations', 'loss_classifier', 'loss_box_reg', 'loss_objectness', 'loss_rpn_box_reg', 'loss_total', 'width', 'height']\n",
    "        scatter_overview = scatter_plot_with_gui(\n",
    "            self.dataset.base_data[self.dataset.base_data[\"is_prediction\"] == True], \n",
    "            x_cols=axis_cols[1:] + [axis_cols[0]],\n",
    "            y_cols=axis_cols,\n",
    "            color_cols=[\"label\", \"num_annotations\", \"filename\"]\n",
    "        )\n",
    "        \n",
    "        cat_2d_hist = categorical_2d_histogram_with_gui(\n",
    "            self.dataset.base_data[self.dataset.base_data[\"is_prediction\"] == True],\n",
    "            category_cols=[\"label\", \"num_annotations\", \"filename\"], \n",
    "            hist_cols=['loss_total', 'loss_classifier', 'loss_box_reg', 'loss_objectness', 'loss_rpn_box_reg', 'score', 'area_normalized', 'area', 'bbox_ratio', 'bbox_width', 'bbox_height', 'num_annotations', 'width', 'height', 'label']\n",
    "        )\n",
    "        \n",
    "        sub_tabs = pn.Tabs(\n",
    "            (\"Histograms\", pn.Row(pn.Spacer(sizing_mode=\"stretch_width\"), scatter_overview, pn.Spacer(sizing_mode=\"stretch_width\"), cat_2d_hist, pn.Spacer(sizing_mode=\"stretch_width\"), align=\"center\")),\n",
    "            (\"Gallery\", Gallery(self.dataset, \"base_data\", \"filepath\", sort_cols=[\"loss_total\", \"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\"], height=self.height).show())\n",
    "        )\n",
    "        \n",
    "        return pn.Column(loss_hists_col, sub_tabs)\n",
    "    \n",
    "    def build_ap_overview(self, metric_data):\n",
    "        map_data = {key: [metric_data[key][\"map\"], int(len(metric_data[key].keys())-1)] for key in metric_data.keys()}\n",
    "        map_table = table_from_dataframe(pd.DataFrame(map_data, index=[\"mAP\", \"Classes\"]).round(4))\n",
    "\n",
    "        ap_data = {}\n",
    "        for metric_key, metric_value in metric_data.items():\n",
    "            if metric_key != \"map\":\n",
    "                ap_data[metric_key] = {\"class\": [], \"ap\": []}\n",
    "                for class_name, class_data in metric_value.items():\n",
    "                    if class_name != \"map\":\n",
    "                        ap_data[metric_key][\"class\"].append(class_name)\n",
    "                        ap_data[metric_key][\"ap\"].append(class_data[\"ap\"])\n",
    "        ap_plots = []\n",
    "        for ap_key, ap_value in ap_data.items():\n",
    "            if len(ap_value[\"ap\"]) > 0:\n",
    "                ap = np.array(ap_value[\"ap\"])[np.array(ap_value[\"ap\"]).argsort()]\n",
    "                class_names = np.array(ap_value[\"class\"])[np.array(ap_value[\"ap\"]).argsort()]\n",
    "                ap_plot = barplot(ap, class_names, bar_type=\"horizontal\")\n",
    "                ap_plot.add_tools(HoverTool(tooltips = [(\"AP\", \"@y @right\")]))\n",
    "                ap_plot.title = Title(text=\"mAP - \" + str(metric_data[ap_key][\"map\"].round(4)), align=\"center\")\n",
    "                ap_plots.append(pn.Column(\"<b>\"+ap_key.replace(\"_\", \" \").title().replace(\"Ap\", \"AP\")+\"</b>\", ap_plot))\n",
    "        \n",
    "        return pn.Column(pn.Row(map_table, align=\"center\"), pn.Row(*ap_plots, align=\"center\"))\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall_plot_bokeh(data, iou):\n",
    "        plot_data = pd.DataFrame({key: data[key] for key in [\"recall\", \"precision\", \"scores\", \"tp\", \"fp\", \"fn\"]})\n",
    "        source = ColumnDataSource(plot_data)\n",
    "        p = figure(x_axis_type=None, height=350, width=400, title=\"AP@\"+str(iou)+\" - \"+str(round(data[\"ap\"],4)), y_axis_label=\"precision\", tools=\"\")\n",
    "        p.line(\"recall\", \"precision\", source=source, legend_label=\"Actual\", color=\"black\", line_width=2)\n",
    "        p.step(data[\"ap11_recalls\"], data[\"ap11_precisions\"], legend_label=\"AP11\", color=\"green\", line_width=2)\n",
    "        p.step(data[\"monotonic_recalls\"], data[\"monotonic_precisions\"], legend_label=\"Monotonic\", color=\"firebrick\", line_width=2)\n",
    "        p.add_tools(HoverTool(tooltips=[(\"Score\", \"@scores\"), (\"TP\", \"@tp\"), (\"FP\", \"@fp\"), (\"FN\", \"@fn\")], mode=\"vline\"))\n",
    "        p.js_on_event(events.DoubleTap, toggle_legend_js(p))\n",
    "        p.legend.click_policy=\"hide\"\n",
    "        p_score = figure(x_range=p.x_range, height=150, width=400, x_axis_label=\"recall\", y_axis_label=\"score\", tools=\"\")\n",
    "        p_score.scatter(data[\"recall\"], data[\"scores\"])\n",
    "        return pn.Row(gridplot([[p],[p_score]]))\n",
    "    \n",
    "    def plot_precision_recall_curves_for_class_bokeh(self, data, class_key):\n",
    "        plot_list = []\n",
    "        for iou, plot_data in data.items():\n",
    "            if iou != \"ap\":\n",
    "                plot_list.append(self.precision_recall_plot_bokeh(plot_data, iou))\n",
    "        return plots_as_matrix(plot_list, 5, 2, width=400*5, height=500*2)\n",
    "    \n",
    "    def plot_additional_stats_bokeh(self, class_data, class_name):\n",
    "        # histograms\n",
    "        hist = histogram(list(class_data.values()))\n",
    "        return pn.pane.Bokeh(hist)\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall_plot_matplotlib(fig, data, iou, bottom, top, left, right):\n",
    "        gs = fig.add_gridspec(nrows=4, ncols=1, left=left, right=right, bottom=bottom, top=top, hspace=0)\n",
    "        ax1 = fig.add_subplot(gs[:3, :])\n",
    "        ax1.set_title(\"IOU: \" + str(iou))\n",
    "        ax1.plot(data[\"recall\"], data[\"precision\"], label=\"Actual\", color=\"black\", lw=2)\n",
    "        ax1.plot(data[\"ap11_recalls\"], data[\"ap11_precisions\"], label=\"AP11\", color=\"green\", lw=2)\n",
    "        ax1.plot(data[\"monotonic_recalls\"], data[\"monotonic_precisions\"], label=\"Montonic\", color=\"firebrick\", lw=2)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_ylabel(\"Precision\")\n",
    "        ax1.legend()\n",
    "        ax2 = fig.add_subplot(gs[-1, :])\n",
    "        ax2.plot(data[\"recall\"], data[\"scores\"], \".\")\n",
    "        ax2.set_xlabel(\"Recall\")\n",
    "        ax2.set_ylabel(\"Score\")\n",
    "\n",
    "    def plot_precision_recall_curves_for_class_matplotlib(self, data, class_key):\n",
    "        fig = plt.figure(constrained_layout=False, figsize=(16,9))\n",
    "        row_coords = [(0.55, 0.95), (0.05, 0.45)]\n",
    "        col_coords = [(0.05, 0.2), (0.25, 0.4), (0.45, 0.6), (0.65, 0.8), (0.85, 1)]\n",
    "        coord_combinations = list(itertools.product(row_coords, col_coords))\n",
    "        ious = sorted([iou for iou in data.keys() if iou != \"ap\"])\n",
    "        for index, iou in enumerate(ious):\n",
    "            if iou != \"ap\":\n",
    "                row_coord = coord_combinations[index][0]\n",
    "                col_coord = coord_combinations[index][1]\n",
    "                self.precision_recall_plot_matplotlib(fig, data[iou], iou, row_coord[0], row_coord[1], col_coord[0], col_coord[1])\n",
    "        plt.close()\n",
    "        return pn.pane.Matplotlib(fig, width=self.width)\n",
    "    \n",
    "    def plot_additional_stats_matplotlib(self, class_data, class_name):\n",
    "        # histograms\n",
    "        class_data[0.5][\"additional_stats\"]\n",
    "        hist_fig, hist_ax = plt.subplots(1, len(class_data[0.5][\"additional_stats\"]), figsize=(9*len(class_data[0.5][\"additional_stats\"]), 9))\n",
    "        for ax, (stat_name, stat_data) in zip(hist_ax, class_data[0.5][\"additional_stats\"].items()):\n",
    "            ax.hist(stat_data, bins=20)\n",
    "            ax.set_xlabel(\" \".join(stat_name.split(\"_\")).title(), fontsize=32)\n",
    "            ax.set_ylabel(\"Counts\", fontsize=32)\n",
    "            ax.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "            ax.xaxis.offsetText.set_fontsize(34)\n",
    "            for x_tick, y_tick in zip(ax.xaxis.get_major_ticks(),  ax.yaxis.get_major_ticks()):\n",
    "                x_tick.label.set_fontsize(34)\n",
    "                y_tick.label.set_fontsize(34)\n",
    "            for x_tick, y_tick in zip(ax.xaxis.get_minor_ticks(),  ax.yaxis.get_minor_ticks()):\n",
    "                x_tick.label.set_fontsize(34)\n",
    "                y_tick.label.set_fontsize(34)\n",
    "        plt.tight_layout()\n",
    "        plt.close()\n",
    "        return pn.pane.Matplotlib(hist_fig, width=self.width)\n",
    "    \n",
    "    def build_precison_recall_overview(self, data):\n",
    "        if len(data) == 1:\n",
    "            return pn.Column(\"<h1> No information available</h1>\")\n",
    "        class_select = pnw.Select(options=[key for key in data.keys() if key != \"map\"])\n",
    "        @pn.depends(class_select.param.value)\n",
    "        def _plot(class_name):\n",
    "            heading = pn.Row(\"<h1>AP - \"+str(data[class_name][\"ap\"].round(4))+\"</h1>\", align=\"center\")\n",
    "            table_data = {\"AP\": [round(data[class_name][iou_key][\"ap\"],4) for iou_key in data[class_name].keys() if iou_key != \"ap\"]}\n",
    "            table_df = pd.DataFrame(table_data).T\n",
    "            table_df.columns = [iou_key for iou_key in data[class_name].keys() if iou_key != \"ap\"]\n",
    "            table_df.index.names = [\"iou\"]\n",
    "            overview_table = table_from_dataframe(table_df)\n",
    "            if self.plotting_backend == \"bokeh\":\n",
    "                precision_recall_curves = self.plot_precision_recall_curves_for_class_bokeh(data[class_name], class_name)\n",
    "                if \"additional_stats\" in next(iter(data[class_name].values())).keys():\n",
    "                    additional_stats_plot = self.plot_additional_stats_bokeh(data[class_name], class_name)\n",
    "                    return pn.Column(heading, pn.Row(overview_table, align=\"center\"), precision_recall_curves, additional_stats_plot)\n",
    "            else:\n",
    "                precision_recall_curves = self.plot_precision_recall_curves_for_class_matplotlib(data[class_name], class_name)\n",
    "                if \"additional_stats\" in next(iter(data[class_name].values())).keys():\n",
    "                    additional_stats_plot = self.plot_additional_stats_matplotlib(data[class_name], class_name)\n",
    "                    return pn.Column(heading, pn.Row(overview_table, align=\"center\"), precision_recall_curves, additional_stats_plot)\n",
    "            return pn.Column(heading, pn.Row(overview_table, align=\"center\"), precision_recall_curves)\n",
    "        return pn.Column(class_select, _plot, width=self.width)\n",
    "    \n",
    "    def build_precision_recall_tab(self):\n",
    "        overview_tab = self.build_ap_overview(self.dataset.metric_data_ap)\n",
    "        ap_tab = self.build_precison_recall_overview(self.dataset.metric_data_ap[\"AP\"])\n",
    "        ap_small_tab = self.build_precison_recall_overview(self.dataset.metric_data_ap[\"AP_small\"])\n",
    "        ap_medium_tab = self.build_precison_recall_overview(self.dataset.metric_data_ap[\"AP_medium\"])\n",
    "        ap_large_tab = self.build_precison_recall_overview(self.dataset.metric_data_ap[\"AP_large\"])\n",
    "        \n",
    "        return pn.Tabs((\"Overview\", overview_tab), (\"AP\", ap_tab), (\"AP_small\", ap_small_tab), (\"AP_medium\", ap_medium_tab), (\"AP_large\", ap_large_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odrd = ObjectDetectionResultsDataset.load(\"test_data/fridge_train.dat\")\n",
    "odrdash = ObjectDetectionResultOverview(odrd, width=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odrdash.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
