{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dashboards\n",
    "> Supplies dashboards to investigate datasets and training results. Dashboards are defined as classes, to show the dashboard use the .show() function on an dashboard instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Union, Optional, List\n",
    "from abc import abstractmethod, ABC\n",
    "from math import ceil, floor\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from bokeh.plotting import show, output_notebook, gridplot, figure\n",
    "from bokeh.models.widgets import DataTable, TableColumn, HTMLTemplateFormatter\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Title\n",
    "from bokeh import events\n",
    "\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from icevision_dashboards.core.dashboards import *\n",
    "from icevision_dashboards.plotting import *\n",
    "from icevision_dashboards.core.data import *\n",
    "from icevision_dashboards.data import *\n",
    "from icevision_dashboards.plotting.utils import toggle_legend_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icedata\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = icedata.fridge.load_data()\n",
    "test_class_map = icedata.fridge.class_map()\n",
    "test_parser = icedata.fridge.parser(test_data_dir)\n",
    "test_train_records, test_valid_records = test_parser.parse()\n",
    "test_valid_record_dataset = BboxRecordDataset(test_valid_records, test_class_map)\n",
    "test_train_record_dataset = BboxRecordDataset(test_train_records, test_class_map)\n",
    "test_very_large_record_dataset = BboxRecordDataset(test_valid_records._records._list*10, test_class_map)\n",
    "test_record_dataset_no_class_map = BboxRecordDataset(test_train_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path_instance_segmentation = icedata.pennfudan.load_data()\n",
    "test_instance_segmentation_parser = icedata.pennfudan.parser(data_dir=test_data_path_instance_segmentation)\n",
    "test_instance_segmentation_train_records, test_instance_segmentation_valid_records = test_instance_segmentation_parser.parse()\n",
    "test_instance_segmentation_class_map = test_instance_segmentation_train_records[0].detection.class_map\n",
    "test_instance_segmentation_valid_record_dataset = InstanceSegmentationRecordDataset(test_instance_segmentation_valid_records, test_instance_segmentation_class_map)\n",
    "test_instance_segmentation_train_record_dataset = InstanceSegmentationRecordDataset(test_instance_segmentation_train_records, test_instance_segmentation_class_map)\n",
    "test_instance_segmentation_very_large_record_dataset = InstanceSegmentationRecordDataset(test_instance_segmentation_valid_records._records._list*10, test_instance_segmentation_class_map)\n",
    "test_instance_segmentation_record_dataset_no_class_map = InstanceSegmentationRecordDataset(test_instance_segmentation_train_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionDatasetOverview(DatasetOverview):\n",
    "    \"\"\"Dataset overview for ObjectDetectionRecordDatasets\"\"\"\n",
    "    DESCRIPTOR_DATA = \"data\"\n",
    "    DESCRIPTOR_STATS_DATASET = \"stats_dataset\"\n",
    "    DESCRIPTOR_STATS_IMAGES = \"stats_image\"\n",
    "    DESCRIPTOR_STATS_ANNOTATIONS = \"stats_class\"\n",
    "    \n",
    "    # change these \n",
    "    IMAGE_IDENTIFIER_COL = \"filepath\"\n",
    "    ANNOTATON_LABEL_COL = \"label\"\n",
    "    OBJECTS_PER_IMAGE_COL = \"num_annotations\"\n",
    "    AREA_COL = \"area\"\n",
    "    \n",
    "    def __init__(self, dataset: GenericDataset, height: int = 500, width: int = 500):\n",
    "        super().__init__(dataset, height, width)\n",
    "        _, cluster_centers, _ = self._run_kmeans_clustering(3)\n",
    "        self.aspect_ratios = cluster_centers\n",
    "    \n",
    "    def _run_kmeans_clustering(self, number_of_clusters, max_iter=1000):\n",
    "        normalized_aspect_ratios = self.dataset.data[\"bbox_ratio\"].values\n",
    "        kmeans = KMeans(init='random', n_clusters=number_of_clusters, random_state=0, max_iter=max_iter)\n",
    "        predictions = kmeans.fit_predict(X=np.expand_dims(normalized_aspect_ratios, -1))\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "        return predictions, cluster_centers, normalized_aspect_ratios\n",
    "    \n",
    "    def _generate_anchor_tab(self):\n",
    "        num_clusters = pnw.NumberInput(name=\"Number of aspect ratios\", value=3, width=self.width, height=50)\n",
    "        num_bins = pnw.NumberInput(name=\"Bins\", value=30, width=self.width, height=50)\n",
    "        \n",
    "        @pn.depends(num_clusters.param.value, num_bins.param.value)\n",
    "        def _plot(num_clusters, bins):\n",
    "            nonlocal self\n",
    "            predictions, cluster_centers, normalized_aspect_ratios = self._run_kmeans_clustering(num_clusters)\n",
    "            self.aspect_ratios = cluster_centers\n",
    "            fig, ax = plt.subplots(1,1, figsize=(16,9))\n",
    "            for pred_label, center in enumerate(cluster_centers):\n",
    "                ax.hist(normalized_aspect_ratios[predictions==pred_label], bins=bins, range=(normalized_aspect_ratios.min(), normalized_aspect_ratios.max()), label=f\"Center: {round(float(center), 2)}\")\n",
    "                ax.set_xlabel(\"Aspect ratios\", fontsize=24)\n",
    "                ax. tick_params(axis='both', labelsize=20)\n",
    "            ax.legend(fontsize=25)\n",
    "            plt.close()\n",
    "            return pn.Column(\n",
    "                pnw.TextInput(name=\"Aspect Ratios\", value=f\"{[round(float(i), 2) for i in cluster_centers]}\", align=\"center\", disabled=True, width=self.width, height=50),\n",
    "                pn.pane.Matplotlib(fig, width=int((self.height-150)*(16/9)), height=self.height-150, align=\"center\")\n",
    "            )\n",
    "        return pn.Column(num_clusters, num_bins, _plot)\n",
    "    \n",
    "    def _generate_datset_stats_tab(self):\n",
    "        dataset_overview_table = table_from_dataframe(getattr(self.dataset, self.DESCRIPTOR_STATS_DATASET), width=self.width, height=self.height//7)\n",
    "        images_overview_table = table_from_dataframe(getattr(self.dataset, self.DESCRIPTOR_STATS_IMAGES), width=self.width, height=self.height//7)\n",
    "        classes_overview_table = table_from_dataframe(getattr(self.dataset, self.DESCRIPTOR_STATS_ANNOTATIONS), width=self.width, height=self.height//4)\n",
    "        \n",
    "        class_occurances = self.dataset.data.groupby(\"label\").count()[\"id\"]\n",
    "        class_occurance_barplot = barplot(counts=class_occurances.values, values=np.array(class_occurances.index), bar_type=\"vertical\", height=(self.height//5)*2)\n",
    "\n",
    "        return pn.Column(\"<b>Dataset stats</b>\", dataset_overview_table, \"<b>Image stats</b>\", images_overview_table, \"<b>Class stats</b>\", classes_overview_table, pn.Row(class_occurance_barplot, align=\"center\"))\n",
    "    \n",
    "    def _generate_annotations_tab(self):\n",
    "        plot_width, plot_height = floor(self.width*0.45), floor(self.height*0.45)\n",
    "        # mixing of classes\n",
    "        mixing_matrix_classes_in_images = utils.calculate_mixing_matrix(getattr(self.dataset, self.DESCRIPTOR_DATA), self.IMAGE_IDENTIFIER_COL, self.ANNOTATON_LABEL_COL)\n",
    "        self.class_mixing_matrix_plot = pn.Column(\"<b>Class mixing</b>\", heatmap(mixing_matrix_classes_in_images, \"row_name\", \"col_name\", \"values\", width=plot_width, height=plot_height), height=self.height)\n",
    "        # number of object per image, stacked hist\n",
    "        self.classes_for_objects_per_image_stacked_hist = pn.Column(\n",
    "            \"<b>Objects per Image</b>\", \n",
    "            stacked_hist(getattr(self.dataset, self.DESCRIPTOR_DATA), self.OBJECTS_PER_IMAGE_COL, self.ANNOTATON_LABEL_COL, \"Objects per Image\", width=plot_width, height=plot_height)\n",
    "        )\n",
    "        # categorical overview\n",
    "        self.categorical_2d_histogram = categorical_2d_histogram_with_gui(\n",
    "            getattr(self.dataset, self.DESCRIPTOR_DATA),\n",
    "            category_cols=[\"label\", \"num_annotations\", \"width\", \"height\"],\n",
    "            hist_cols=[\"num_annotations\", \"area\", \"area_normalized\", \"area_square_root\", \"area_square_root_normalized\", \"bbox_ratio\", \"bbox_xmin\", \"bbox_xmax\", \"bbox_ymin\", \"bbox_ymax\", \"width\", \"height\"],\n",
    "            height=self.height//2, width=self.width//2\n",
    "        )\n",
    "        # ratio distribution\n",
    "        grid =  pn.GridSpec(ncols=2,nrows=2, width=self.width, height=self.height, align=\"center\")\n",
    "        grid[0,0] = self.class_mixing_matrix_plot\n",
    "        grid[1,0] = self.classes_for_objects_per_image_stacked_hist\n",
    "        grid[:,1] = pn.Column(self.categorical_2d_histogram, align=\"center\")\n",
    "        return grid \n",
    "    \n",
    "    def _generate_gallery_tab(self):\n",
    "        return pn.Column(RecordDastasetGallery(self.dataset, \"data\", \"filepath\", [\"num_annotations\", \"width\", \"height\", \"label\", \"area\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\"], height=self.height).show(), align=\"center\", sizing_mode=\"stretch_both\")\n",
    "    \n",
    "    def build_gui(self):\n",
    "        dataset_tab = super()._generate_dataset_tab()\n",
    "        dataset_stats_tab = self._generate_datset_stats_tab()\n",
    "        annotations_tab = self._generate_annotations_tab()\n",
    "        anchor_tab = self._generate_anchor_tab()\n",
    "        gallery_tab = self._generate_gallery_tab()\n",
    "        self.gui = pn.Tabs((\"Dataset stats\", dataset_stats_tab), (\"Annotations\", annotations_tab), (\"Aspect Ratios\", anchor_tab), (\"Gallery\", gallery_tab), (\"Dataset\", dataset_tab), align=\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_overview = ObjectDetectionDatasetOverview(test_valid_record_dataset, width=1500, height=900)\n",
    "test_object_detection_overview.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionDatasetComparison(DatasetComparison):\n",
    "    \"\"\"Dataset comparison for ObjectDetectionRecordDatasets.\"\"\"\n",
    "    DESCRIPTOR_DATA = \"data\"\n",
    "    DESCRIPTOR_STATS_DATASET = \"stats_dataset\"\n",
    "    DESCRIPTOR_STATS_IMAGES = \"stats_image\"\n",
    "    DESCRIPTOR_STATS_ANNOTATIONS = \"stats_class\"\n",
    "    \n",
    "    # change these \n",
    "    IMAGE_IDENTIFIER_COL = \"filepath\"\n",
    "    ANNOTATON_LABEL_COL = \"label\"\n",
    "    OBJECTS_PER_IMAGE_COL = \"num_annotations\"\n",
    "    AREA_COL = \"area\"\n",
    "    \n",
    "    def _generate_dataset_tab(self):\n",
    "        overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA), width=floor(self.width/2), height=self.height)\n",
    "        return pn.Row(*overview_table)\n",
    "    \n",
    "    def _generate_datset_stats_tab(self):\n",
    "        dataset_overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_STATS_DATASET), width=floor(self.width/2), height=self.height//7)\n",
    "        images_overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_STATS_IMAGES), width=floor(self.width/2), height=self.height//7)\n",
    "        classes_overview_table = table_from_dataframe(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_STATS_ANNOTATIONS), width=floor(self.width/2), height=self.height//4)\n",
    "        \n",
    "        class_occurances_values = [dataset.data.groupby(\"label\").count()[\"id\"].values for dataset in self.datasets]\n",
    "        class_occurances_index = [np.array(dataset.data.groupby(\"label\").count()[\"id\"].index) for dataset in self.datasets]\n",
    "        class_occurance_barplot = barplot(counts=class_occurances_values, values=class_occurances_index, bar_type=\"vertical\", height=(self.height//5)*2, width=floor(self.width/2))\n",
    "\n",
    "        dublication_data = {dataset.name if dataset.name is not None else \"Dataset_\"+str(index): [getattr(dataset, self.DESCRIPTOR_DATA).duplicated().sum()] for index, dataset in enumerate(self.datasets)}\n",
    "        dublication_data[\"All\"] = pd.concat(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA)).duplicated().sum()\n",
    "        dublication_df = pd.DataFrame(dublication_data)\n",
    "        dublication_overview = table_from_dataframe(dublication_df)\n",
    "        \n",
    "        return pn.Column(\n",
    "            \"<b>Dublications</p>\", pn.Row(dublication_overview), \n",
    "            \"<b>Dataset stats</b>\", pn.Row(*dataset_overview_table), \n",
    "            \"<b>Image stats</b>\", pn.Row(*images_overview_table), \n",
    "            \"<b>Class stats</b>\", pn.Row(*classes_overview_table), \n",
    "            pn.Row(*class_occurance_barplot, align=\"center\")\n",
    "        )\n",
    "    \n",
    "    def _generate_annotations_tab(self):\n",
    "        plot_size = min(floor(self.width/len(self.datasets)), floor(self.height/2))\n",
    "        link_plots_checkbox = pnw.Checkbox(name=\"Link plot axis\", value=False)\n",
    "        \n",
    "        @pn.depends(link_plots_checkbox.param.value)\n",
    "        def _mixing_plots(link_plots):\n",
    "            # mixing of classes\n",
    "            mixing_matrix_classes_in_images = [utils.calculate_mixing_matrix(dataset, self.IMAGE_IDENTIFIER_COL, self.ANNOTATON_LABEL_COL) for dataset in self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA)]\n",
    "            class_mixing_matrix_plot = pn.Row(\"<b>Class mixing</b>\", *heatmap(mixing_matrix_classes_in_images, \"row_name\", \"col_name\", \"values\", link_plots=link_plots, width=plot_size, height=plot_size))\n",
    "            # number of object per image, stacked hist\n",
    "            classes_for_objects_per_image_stacked_hist = pn.Row(\n",
    "                \"<b>Objects per Image</b>\", \n",
    "                *stacked_hist(self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA), self.OBJECTS_PER_IMAGE_COL, self.ANNOTATON_LABEL_COL, \"Objects per Image\", link_plots=link_plots, width=plot_size, height=plot_size)\n",
    "            )\n",
    "            return pn.Column(link_plots_checkbox, class_mixing_matrix_plot, classes_for_objects_per_image_stacked_hist)\n",
    "            \n",
    "        # categorical overview\n",
    "        self.categorical_2d_histogram = categorical_2d_histogram_with_gui(\n",
    "            self._get_descriptor_for_all_datasets(self.DESCRIPTOR_DATA),\n",
    "            category_cols=[\"label\", \"num_annotations\", \"width\", \"height\"],\n",
    "            hist_cols=[\"num_annotations\", \"area\", \"area_normalized\", \"area_square_root\", \"area_square_root_normalized\", \"bbox_ratio\", \"bbox_xmin\", \"bbox_xmax\", \"bbox_ymin\", \"bbox_ymax\", \"bbox_width\", \"bbox_height\", \"width\", \"height\"],\n",
    "            height=floor(plot_size*1.5), width=floor(plot_size*1.5)\n",
    "        )\n",
    "        return pn.Row(_mixing_plots, self.categorical_2d_histogram, align=\"center\")\n",
    "    \n",
    "    def _generate_gallery_tab(self):\n",
    "        return pn.Row(*[RecordDastasetGallery(dataset, \"data\", \"filepath\", [\"num_annotations\", \"width\", \"height\", \"label\", \"area\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\"], width=floor(self.width/len(self.datasets))).show() for dataset in self.datasets], align=\"start\", sizing_mode=\"stretch_both\")\n",
    "    \n",
    "    def build_gui(self):\n",
    "        dataset_tab = self._generate_dataset_tab()\n",
    "        dataset_stats_tab = self._generate_datset_stats_tab()\n",
    "        annotations_tab = self._generate_annotations_tab()\n",
    "        gallery_tab = self._generate_gallery_tab()\n",
    "        self.gui = pn.Tabs((\"Dataset stats overview\", dataset_stats_tab), (\"Annotations overivew\", annotations_tab), (\"Gallery\", gallery_tab), (\"Dataset overview\", dataset_tab), align=\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_comparison = ObjectDetectionDatasetComparison([test_valid_record_dataset, test_train_record_dataset], width=1700, height=700)\n",
    "test_object_detection_comparison.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionDatasetGeneratorScatter(DatasetGeneratorScatter):\n",
    "    \"\"\"Dataset generator for ObjectDetectionRecordDatasets\"\"\"\n",
    "    DESCRIPTOR_STATS = \"stats_dataset\"\n",
    "    DATASET_OVERVIEW = ObjectDetectionDatasetOverview\n",
    "    DATASET_FILTER_COLUMNS = [\"width\", \"height\", \"label\", \"area_normalized\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"num_annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_generator = ObjectDetectionDatasetGeneratorScatter(test_valid_record_dataset, height=700, width=1000)\n",
    "test_dataset_generator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionDatasetGeneratorRange(DatasetGenerator):\n",
    "    \"\"\"Dataset generator for ObjectDetectionRecordDatasets\"\"\"\n",
    "    DESCRIPTOR_STATS = \"stats_dataset\"\n",
    "    DATASET_OVERVIEW = ObjectDetectionDatasetOverview\n",
    "    DATASET_FILTER_COLUMNS = [\"width\", \"height\", \"label\", \"area_normalized\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"num_annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_generator = ObjectDetectionDatasetGeneratorRange(test_valid_record_dataset, height=700, width=1000)\n",
    "test_dataset_generator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionResultOverview(Dashboard):\n",
    "    \"\"\"Result dashboard for instance segmentation results. Init tasks an InstanceSegmentationResultDataset\"\"\"\n",
    "    def __init__(self, dataset, height=700, width=1000):\n",
    "        self.dataset= dataset\n",
    "        self.accordion_active = [0]\n",
    "        self.loss_keys = [key for key in self.dataset.base_data.columns if \"loss\" in key]        \n",
    "        super().__init__(width=width, height=height)\n",
    "        \n",
    "    def build_gui(self):\n",
    "        self.loss_tab = self.build_loss_tab()\n",
    "        self.ap_tab = self.build_precision_recall_tab()\n",
    "        self.gui = pn.Tabs((\"Loss\", self.loss_tab), (\"Precision-Recall\", self.ap_tab))\n",
    "    \n",
    "    def show(self):\n",
    "        return self.gui\n",
    "    \n",
    "    def show_loss_tab(self):\n",
    "        return self.loss_tab\n",
    "    \n",
    "    def show_ap_tab(self):\n",
    "        return self.ap_tab\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_grid_coodinates(num_centers, center_spacer_ratio=3.5):\n",
    "        num_spacers = num_centers+1\n",
    "        spacer_size = 1/(num_spacers*center_spacer_ratio)\n",
    "        center_size = (1-num_spacers*spacer_size)/num_centers\n",
    "        coordinates = []\n",
    "        coordinate1 = 0\n",
    "        coordinate = spacer_size\n",
    "        for i in range(num_spacers + num_centers - 1):\n",
    "            if i%2:\n",
    "                coordinate += spacer_size\n",
    "            else:\n",
    "                coordinates.append((coordinate, coordinate+center_size))\n",
    "                coordinate += center_size\n",
    "        return coordinates\n",
    "    \n",
    "    def build_loss_tab(self):\n",
    "        # loss hists\n",
    "        fig_loss_hists, ax_loss_hists = plt.subplots(1, len(self.loss_keys), figsize=(16*5,9))\n",
    "        unique_losses = self.dataset.base_data[[\"filepath\"] + self.loss_keys].drop_duplicates()\n",
    "        for single_ax, key in zip(ax_loss_hists, self.loss_keys):\n",
    "            single_ax.hist(unique_losses[key].values, bins=20)\n",
    "            single_ax.set_title(\" \".join(key.split(\"_\")).title(), fontsize=40)\n",
    "            for tick in single_ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(34)\n",
    "                tick.label.set_rotation(45)\n",
    "            for tick in single_ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(34)\n",
    "        plt.tight_layout()\n",
    "        plt.close()\n",
    "        loss_hists_col = pn.pane.Matplotlib(fig_loss_hists, width=self.width)\n",
    "        axis_cols = ['score', 'area_normalized', 'area', 'bbox_ratio', 'bbox_width', 'bbox_height', 'num_annotations'] + self.loss_keys + ['width', 'height']\n",
    "        scatter_overview = scatter_plot_with_gui(\n",
    "            self.dataset.base_data[self.dataset.base_data[\"is_prediction\"] == True], \n",
    "            x_cols=axis_cols[1:] + [axis_cols[0]],\n",
    "            y_cols=axis_cols,\n",
    "            color_cols=[\"label\", \"num_annotations\", \"filename\"]\n",
    "        )\n",
    "        \n",
    "        cat_2d_hist = categorical_2d_histogram_with_gui(\n",
    "            self.dataset.base_data[self.dataset.base_data[\"is_prediction\"] == True],\n",
    "            category_cols=[\"label\", \"num_annotations\", \"filename\"], \n",
    "            hist_cols=self.loss_keys + ['score', 'area_normalized', 'area', 'bbox_ratio', 'bbox_width', 'bbox_height', 'num_annotations', 'width', 'height', 'label']\n",
    "        )\n",
    "        \n",
    "        sub_tabs = pn.Tabs(\n",
    "            (\"Histograms\", pn.Row(pn.Spacer(sizing_mode=\"stretch_width\"), scatter_overview, pn.Spacer(sizing_mode=\"stretch_width\"), cat_2d_hist, pn.Spacer(sizing_mode=\"stretch_width\"), align=\"center\")),\n",
    "            (\"Gallery\", RecordDastasetGallery(self.dataset, \"base_data\", \"filepath\", sort_cols=self.loss_keys, height=self.height).show())\n",
    "        )\n",
    "        \n",
    "        return pn.Column(loss_hists_col, sub_tabs)\n",
    "    \n",
    "    def build_ap_overview(self, metric_data):\n",
    "        map_data = {key: [metric_data[key][\"map\"], int(len(metric_data[key].keys())-1)] for key in metric_data.keys()}\n",
    "        map_table = table_from_dataframe(pd.DataFrame(map_data, index=[\"mAP\", \"Classes\"]).round(4))\n",
    "\n",
    "        ap_data = {}\n",
    "        for metric_key, metric_value in metric_data.items():\n",
    "            if metric_key != \"map\":\n",
    "                ap_data[metric_key] = {\"class\": [], \"ap\": []}\n",
    "                for class_name, class_data in metric_value.items():\n",
    "                    if class_name != \"map\":\n",
    "                        ap_data[metric_key][\"class\"].append(class_name)\n",
    "                        ap_data[metric_key][\"ap\"].append(class_data[\"ap\"])\n",
    "        ap_plots = []\n",
    "        for ap_key, ap_value in ap_data.items():\n",
    "            if len(ap_value[\"ap\"]) > 0:\n",
    "                ap = np.array(ap_value[\"ap\"])[np.array(ap_value[\"ap\"]).argsort()]\n",
    "                class_names = np.array(ap_value[\"class\"])[np.array(ap_value[\"ap\"]).argsort()]\n",
    "                ap_plot = barplot(ap, class_names, bar_type=\"horizontal\")\n",
    "                ap_plot.add_tools(HoverTool(tooltips = [(\"AP\", \"@y @right\")]))\n",
    "                ap_plot.title = Title(text=\"mAP - \" + str(metric_data[ap_key][\"map\"].round(4)), align=\"center\")\n",
    "                ap_plots.append(pn.Column(\"<b>\"+ap_key.replace(\"_\", \" \").title().replace(\"Ap\", \"AP\")+\"</b>\", ap_plot))\n",
    "        \n",
    "        return pn.Column(pn.Row(map_table, align=\"center\"), pn.Row(*ap_plots, align=\"center\"))\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall_plot_matplotlib(fig, data, iou, bottom, top, left, right):\n",
    "        gs = fig.add_gridspec(nrows=4, ncols=1, left=left, right=right, bottom=bottom, top=top, hspace=0)\n",
    "        ax1 = fig.add_subplot(gs[:3, :])\n",
    "        ax1.set_title(\"IOU: \" + str(iou))\n",
    "        ax1.plot(data[\"recall\"], data[\"precision\"], label=\"Actual\", color=\"black\", lw=2)\n",
    "        ax1.plot(data[\"ap11_recalls\"], data[\"ap11_precisions\"], label=\"AP11\", color=\"green\", lw=2)\n",
    "        ax1.plot(data[\"monotonic_recalls\"], data[\"monotonic_precisions\"], label=\"Montonic\", color=\"firebrick\", lw=2)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_ylabel(\"Precision\")\n",
    "        ax1.legend()\n",
    "        ax2 = fig.add_subplot(gs[-1, :])\n",
    "        ax2.plot(data[\"recall\"], data[\"scores\"], \".\")\n",
    "        ax2.set_xlabel(\"Recall\")\n",
    "        ax2.set_ylabel(\"Score\")\n",
    "\n",
    "    def plot_precision_recall_curves_for_class_matplotlib(self, data, class_key):\n",
    "        fig = plt.figure(constrained_layout=False, figsize=(16,9))\n",
    "        row_coords = self.generate_grid_coodinates(2)[::-1]\n",
    "        col_coords = self.generate_grid_coodinates(5)\n",
    "        coord_combinations = list(itertools.product(row_coords, col_coords))\n",
    "        ious = sorted([iou for iou in data.keys() if iou != \"ap\"])\n",
    "        for index, iou in enumerate(ious):\n",
    "            if iou != \"ap\":\n",
    "                row_coord = coord_combinations[index][0]\n",
    "                col_coord = coord_combinations[index][1]\n",
    "                self.precision_recall_plot_matplotlib(fig, data[iou], iou, row_coord[0], row_coord[1], col_coord[0], col_coord[1])\n",
    "        plt.close()\n",
    "        return pn.pane.Matplotlib(fig, width=self.width)\n",
    "    \n",
    "    @staticmethod\n",
    "    def histogramm_plot(fig, data, hist_key, bottom, top, left, right, bins=25):\n",
    "        gs = fig.add_gridspec(nrows=1, ncols=1, left=left, right=right, bottom=bottom, top=top, hspace=0)\n",
    "        ax = fig.add_subplot(gs[:, :])\n",
    "        # ax.set_title(hist_key)\n",
    "        if not \"scatter\" in hist_key:\n",
    "            if \"normalized\" in hist_key:\n",
    "                ax.hist(data[hist_key][0], bins=bins, range=(0,1))\n",
    "            else:\n",
    "                ax.hist(data[hist_key][0], bins=bins)\n",
    "            ax.set_xlabel(\" \".join(hist_key.split(\"_\")).title())\n",
    "            ax.set_ylabel(\"Counts\")\n",
    "        elif hist_key == \"used_scatter\":\n",
    "            ax.plot(data[\"used_gt_box_areas_normalized\"][0], data[\"used_pred_box_areas_normalized\"][0], \".\")\n",
    "            ax.set_xlabel('Used Gt Box Areas Normalized')\n",
    "            ax.set_ylabel('Used Pred Box \\nAreas Normalized')\n",
    "        elif hist_key == \"unused_scatter\":\n",
    "            ax.plot(data[\"unused_gt_box_areas_normalized\"][0], data[\"unused_pred_box_areas_normalized\"][0], \".\")\n",
    "            ax.set_xlabel('Unused Gt Box Areas Normalized')\n",
    "            ax.set_ylabel('Unused Pred Box \\nAreas Normalized')\n",
    "        elif hist_key == \"xoffset_vs_yoffset_scatter\":\n",
    "            ax.plot(data[\"x_center_offsets\"][0], data[\"y_center_offsets\"][0], \".\")\n",
    "            ax.set_ylabel(\"Y-Offset\")\n",
    "            ax.set_xlabel(\"X-Offset\")\n",
    "        elif hist_key == \"center_distance_vs_unused_gt_box_area_scatter\":\n",
    "            ax.plot(data[\"center_distances\"][0], data[\"unused_gt_box_areas_normalized\"][0], \".\")\n",
    "            ax.set_ylabel('Unused Gt Box \\nAreas Normalized')\n",
    "            ax.set_xlabel(\"Center Distance\")\n",
    "        elif hist_key == \"center_distance_vs_unused_pred_box_area_scatter\":\n",
    "            ax.plot(data[\"center_distances\"][0], data[\"unused_pred_box_areas_normalized\"][0], \".\")\n",
    "            ax.set_ylabel('Unused Pred Box \\nAreas Normalized')\n",
    "            ax.set_xlabel(\"Center Distance\")\n",
    "    \n",
    "    def plot_additional_stats_matplotlib(self, class_data, class_name):\n",
    "        # histograms\n",
    "        ious = sorted([iou for iou in class_data.keys() if iou != \"ap\"])\n",
    "        iou_selector = pnw.Select(name=\"IOU\", options=ious, value=0.5)\n",
    "        \n",
    "        @pn.depends(iou_selector.param.value)\n",
    "        def _plot_additional_stats_matplotlib(iou):\n",
    "            nonlocal class_data\n",
    "            nonlocal self\n",
    "            data = class_data[iou]\n",
    "            fig = plt.figure(constrained_layout=False, figsize=(16,9))\n",
    "            row_coords = self.generate_grid_coodinates(3)[::-1]\n",
    "            col_coords = self.generate_grid_coodinates(4)[::-1]\n",
    "            coord_combinations = list(itertools.product(col_coords, row_coords))\n",
    "\n",
    "            for index, hist_key in enumerate(\n",
    "                [\n",
    "                    'center_distances', 'y_center_offsets', 'x_center_offsets',  \n",
    "                    'used_scatter', 'unused_gt_box_areas_normalized', 'used_gt_box_areas_normalized',\n",
    "                    'unused_scatter', 'center_distances', 'y_center_offsets', \n",
    "                    'xoffset_vs_yoffset_scatter', 'center_distance_vs_unused_gt_box_area_scatter', \"center_distance_vs_unused_pred_box_area_scatter\",\n",
    "                ]\n",
    "            ):\n",
    "                row_coord = coord_combinations[index][0]\n",
    "                col_coord = coord_combinations[index][1]\n",
    "                self.histogramm_plot(fig, data, hist_key, row_coord[0], row_coord[1], col_coord[0], col_coord[1])\n",
    "            plt.close()\n",
    "            return pn.pane.Matplotlib(fig, width=self.width)\n",
    "        return pn.Column(iou_selector, _plot_additional_stats_matplotlib)\n",
    "    \n",
    "    def build_precison_recall_overview(self, data):\n",
    "        if len(data) == 1:\n",
    "            return pn.Column(\"<h1> No information available</h1>\")\n",
    "        class_select = pnw.Select(options=[key for key in data.keys() if key != \"map\"])\n",
    "        @pn.depends(class_select.param.value)\n",
    "        def _plot(class_name):\n",
    "            heading = pn.Row(\"<h1>AP - \"+str(data[class_name][\"ap\"].round(4))+\"</h1>\", align=\"center\")\n",
    "            table_data = {\"AP\": [round(data[class_name][iou_key][\"ap\"],4) for iou_key in data[class_name].keys() if iou_key != \"ap\"]}\n",
    "            table_df = pd.DataFrame(table_data).T\n",
    "            table_df.columns = [iou_key for iou_key in data[class_name].keys() if iou_key != \"ap\"]\n",
    "            table_df.index.names = [\"iou\"]\n",
    "            overview_table = table_from_dataframe(table_df)\n",
    "            precision_recall_curves = self.plot_precision_recall_curves_for_class_matplotlib(data[class_name], class_name)\n",
    "            additional_stats_plot = self.plot_additional_stats_matplotlib(data[class_name], class_name)\n",
    "            ap_and_additional_stats_accordion = pn.Accordion((\"AP\", pn.Column(class_select, heading, pn.Row(overview_table, align=\"center\"), precision_recall_curves)), (\"Additioanl stats\", additional_stats_plot), active=self.accordion_active)\n",
    "            return pn.Column(ap_and_additional_stats_accordion)\n",
    "        return pn.Column(_plot, width=self.width)\n",
    "    \n",
    "    def build_precision_recall_tab(self):\n",
    "        overview_tab = self.build_ap_overview(self.dataset.metric_data_ap)\n",
    "        ap_tab = self.build_precison_recall_overview(self.dataset.metric_data_ap[\"AP\"])\n",
    "        ap_small_tab = self.build_precison_recall_overview(self.dataset.metric_data_ap[\"AP_small\"])\n",
    "        ap_medium_tab = self.build_precison_recall_overview(self.dataset.metric_data_ap[\"AP_medium\"])\n",
    "        ap_large_tab = self.build_precison_recall_overview(self.dataset.metric_data_ap[\"AP_large\"])\n",
    "        \n",
    "        return pn.Tabs((\"Overview\", overview_tab), (\"AP\", ap_tab), (\"AP_small\", ap_small_tab), (\"AP_medium\", ap_medium_tab), (\"AP_large\", ap_large_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odrd = ObjectDetectionResultsDataset.load(\"test_data/object_detection_result_ds.dat\")\n",
    "\n",
    "# make sure the path in the df are correct\n",
    "odrd.base_data[\"filepath\"] = odrd.base_data[\"filepath\"].apply(lambda x: str(test_data_dir).split(\".icevision\")[0] + \".icevision\" + str(x).split(\".icevision\")[-1])\n",
    "\n",
    "odrdash = ObjectDetectionResultOverview(odrd, width=1500)\n",
    "odrdash.show()\n",
    "odrdash.show_loss_tab()\n",
    "odrdash.show_ap_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InstanceSegmentationDatasetOverview(ObjectDetectionDatasetOverview):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_overview = InstanceSegmentationDatasetOverview(test_instance_segmentation_valid_record_dataset, width=1500, height=900)\n",
    "test_instance_segmentation_overview.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InstanceSegmentationDatasetComparison(ObjectDetectionDatasetComparison):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_comparison = InstanceSegmentationDatasetComparison([test_instance_segmentation_valid_record_dataset, test_instance_segmentation_train_record_dataset], width=1700, height=700)\n",
    "test_instance_segmentation_comparison.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InstanceSegmentationDatasetGeneratorScatter(DatasetGeneratorScatter):\n",
    "    \"\"\"Dataset generator for InstanceSgementationRecordDatasets\"\"\"\n",
    "    DESCRIPTOR_STATS = \"stats_dataset\"\n",
    "    DATASET_OVERVIEW = InstanceSegmentationDatasetOverview\n",
    "    DATASET_FILTER_COLUMNS = [\"width\", \"height\", \"label\", \"mask_area\", \"bbox_area\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"num_annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_dataset_generator = InstanceSegmentationDatasetGeneratorScatter(test_instance_segmentation_train_record_dataset, height=700, width=1000)\n",
    "test_instance_segmentation_dataset_generator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InstanceSegmentationDatasetGeneratorRange(DatasetGenerator):\n",
    "    \"\"\"Dataset generator for InstanceSegmentationRecordDatasets\"\"\"\n",
    "    DESCRIPTOR_STATS = \"stats_dataset\"\n",
    "    DATASET_OVERVIEW = InstanceSegmentationDatasetOverview\n",
    "    DATASET_FILTER_COLUMNS = [\"width\", \"height\", \"label\", \"mask_area\", \"bbox_area\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"num_annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_dataset_generator = InstanceSegmentationDatasetGeneratorRange(test_instance_segmentation_valid_record_dataset, height=700, width=1000)\n",
    "test_instance_segmentation_dataset_generator.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InstanceSegmentationResultOverview(ObjectDetectionResultOverview):\n",
    "    \"\"\"Result dashboard for instance segmentation results. Init tasks an InstanceSegmentationResultDataset\"\"\"\n",
    "    def build_loss_tab(self):\n",
    "        # loss hists\n",
    "        fig_loss_hists, ax_loss_hists = plt.subplots(1, len(self.loss_keys), figsize=(16*5,9))\n",
    "        unique_losses = self.dataset.base_data[[\"filepath\"] + self.loss_keys].drop_duplicates()\n",
    "        for single_ax, key in zip(ax_loss_hists, self.loss_keys):\n",
    "            single_ax.hist(unique_losses[key].values, bins=20)\n",
    "            single_ax.set_title(\" \".join(key.split(\"_\")).title(), fontsize=40)\n",
    "            for tick in single_ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(34)\n",
    "                tick.label.set_rotation(45)\n",
    "            for tick in single_ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(34)\n",
    "        plt.tight_layout()\n",
    "        plt.close()\n",
    "        loss_hists_col = pn.pane.Matplotlib(fig_loss_hists, width=self.width)\n",
    "        axis_cols = ['score', 'mask_area', 'mask_area_normalized', 'mask_area_normalized_by_bbox_area', 'bbox_area_normalized', 'bbox_area', 'bbox_ratio', 'bbox_width', 'bbox_height', 'num_annotations'] + self.loss_keys + ['width', 'height']\n",
    "        scatter_overview = scatter_plot_with_gui(\n",
    "            self.dataset.base_data[self.dataset.base_data[\"is_prediction\"] == True], \n",
    "            x_cols=axis_cols[1:] + [axis_cols[0]],\n",
    "            y_cols=axis_cols,\n",
    "            color_cols=[\"label\", \"num_annotations\", \"filename\"]\n",
    "        )\n",
    "        \n",
    "        cat_2d_hist = categorical_2d_histogram_with_gui(\n",
    "            self.dataset.base_data[self.dataset.base_data[\"is_prediction\"] == True],\n",
    "            category_cols=[\"label\", \"num_annotations\", \"filename\"], \n",
    "            hist_cols=self.loss_keys + ['score', 'mask_area', 'mask_area_normalized', 'mask_area_normalized_by_bbox_area', 'bbox_area_normalized', 'bbox_area', 'bbox_ratio', 'bbox_width', 'bbox_height', 'num_annotations', 'width', 'height', 'label']\n",
    "        )\n",
    "        \n",
    "        sub_tabs = pn.Tabs(\n",
    "            (\"Histograms\", pn.Row(pn.Spacer(sizing_mode=\"stretch_width\"), scatter_overview, pn.Spacer(sizing_mode=\"stretch_width\"), cat_2d_hist, pn.Spacer(sizing_mode=\"stretch_width\"), align=\"center\")),\n",
    "            (\"Gallery\", RecordDastasetGallery(self.dataset, \"base_data\", \"filepath\", sort_cols=self.loss_keys, height=self.height).show())\n",
    "        )\n",
    "        \n",
    "        return pn.Column(loss_hists_col, sub_tabs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def histogramm_plot(fig, data, hist_key, bottom, top, left, right, bins=25):\n",
    "        gs = fig.add_gridspec(nrows=1, ncols=1, left=left, right=right, bottom=bottom, top=top, hspace=0)\n",
    "        ax = fig.add_subplot(gs[:, :])\n",
    "        # ax.set_title(hist_key)\n",
    "        if not \"scatter\" in hist_key:\n",
    "            if \"normalized\" in hist_key:\n",
    "                ax.hist(data[hist_key][0], bins=bins, range=(0,1))\n",
    "            else:\n",
    "                ax.hist(data[hist_key][0], bins=bins)\n",
    "            ax.set_xlabel(\" \".join(hist_key.split(\"_\")).title())\n",
    "            ax.set_ylabel(\"Counts\")\n",
    "        elif hist_key == \"used_scatter\":\n",
    "            ax.plot(data[\"used_gt_mask_areas_normalized\"][0], data[\"used_pred_mask_areas_normalized\"][0], \".\")\n",
    "            ax.set_xlabel('Used Gt Mask Areas Normalized')\n",
    "            ax.set_ylabel('Used Pred Mask \\nAreas Normalized')\n",
    "        elif hist_key == \"unused_scatter\":\n",
    "            ax.plot(data[\"unused_gt_mask_areas_normalized\"][0], data[\"unused_pred_mask_areas_normalized\"][0], \".\")\n",
    "            ax.set_xlabel('Unused Gt Mask Areas Normalized')\n",
    "            ax.set_ylabel('Unused Pred Mask \\nAreas Normalized')\n",
    "        elif hist_key == \"xoffset_vs_yoffset_scatter\":\n",
    "            ax.plot(data[\"x_center_offsets\"][0], data[\"y_center_offsets\"][0], \".\")\n",
    "            ax.set_ylabel(\"Y-Offset\")\n",
    "            ax.set_xlabel(\"X-Offset\")\n",
    "        elif hist_key == \"center_distance_vs_unused_gt_mask_area_scatter\":\n",
    "            ax.plot(data[\"center_distances\"][0], data[\"unused_gt_mask_areas_normalized\"][0], \".\")\n",
    "            ax.set_ylabel('Unused Gt Mask \\nAreas Normalized')\n",
    "            ax.set_xlabel(\"Center Distance\")\n",
    "        elif hist_key == \"center_distance_vs_unused_pred_mask_area_scatter\":\n",
    "            ax.plot(data[\"center_distances\"][0], data[\"unused_pred_mask_areas_normalized\"][0], \".\")\n",
    "            ax.set_ylabel('Unused Pred Mask \\nAreas Normalized')\n",
    "            ax.set_xlabel(\"Center Distance\")\n",
    "    \n",
    "    def plot_additional_stats_matplotlib(self, class_data, class_name):\n",
    "        # histograms\n",
    "        ious = sorted([iou for iou in class_data.keys() if iou != \"ap\"])\n",
    "        iou_selector = pnw.Select(name=\"IOU\", options=ious, value=0.5)\n",
    "        \n",
    "        @pn.depends(iou_selector.param.value)\n",
    "        def _plot_additional_stats_matplotlib(iou):\n",
    "            nonlocal class_data\n",
    "            nonlocal self\n",
    "            data = class_data[iou]\n",
    "            fig = plt.figure(constrained_layout=False, figsize=(16,9))\n",
    "            row_coords = self.generate_grid_coodinates(3)[::-1]\n",
    "            col_coords = self.generate_grid_coodinates(4)[::-1]\n",
    "            coord_combinations = list(itertools.product(col_coords, row_coords))\n",
    "\n",
    "            for index, hist_key in enumerate(\n",
    "                [\n",
    "                    'center_distances', 'y_center_offsets', 'x_center_offsets',  \n",
    "                    'used_scatter', 'unused_gt_mask_areas_normalized', 'used_gt_mask_areas_normalized',\n",
    "                    'unused_scatter', 'center_distances', 'y_center_offsets', \n",
    "                    'xoffset_vs_yoffset_scatter', 'center_distance_vs_unused_gt_mask_area_scatter', \"center_distance_vs_unused_pred_mask_area_scatter\",\n",
    "                ]\n",
    "            ):\n",
    "                row_coord = coord_combinations[index][0]\n",
    "                col_coord = coord_combinations[index][1]\n",
    "                self.histogramm_plot(fig, data, hist_key, row_coord[0], row_coord[1], col_coord[0], col_coord[1])\n",
    "            plt.close()\n",
    "            return pn.pane.Matplotlib(fig, width=self.width)\n",
    "        return pn.Column(iou_selector, _plot_additional_stats_matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isrd = InstanceSegmentationResultsDataset.load(\"test_data/instance_segmentation_result_ds_valid.dat\")\n",
    "isrd = InstanceSegmentationResultsDataset(isrd.base_data.iloc[:10])\n",
    "# make sure the path in the df are correct\n",
    "isrd.base_data[\"filepath\"] = isrd.base_data[\"filepath\"].apply(lambda x: str(test_data_dir).split(\".icevision\")[0] + \".icevision\" + str(x).split(\".icevision\")[-1])\n",
    "\n",
    "isrdash = InstanceSegmentationResultOverview(isrd, width=1500)\n",
    "isrdash.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
