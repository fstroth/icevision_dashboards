{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "> Provides dataset for icevision records and classmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import datetime\n",
    "from typing import Union, Optional, List\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import panel as pn\n",
    "\n",
    "from icevision.core.record import BaseRecord\n",
    "import icevision.parsers as parsers\n",
    "from icevision.data.data_splitter import RandomSplitter\n",
    "from icevision.core.bbox import BBox\n",
    "from icevision.core.class_map import ClassMap\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from icevision_dashboards.plotting.utils import draw_record_with_bokeh\n",
    "from icevision_dashboards.core.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = icedata.fridge.load_data()\n",
    "test_class_map = icedata.fridge.class_map()\n",
    "test_parser = icedata.fridge.parser(test_data_dir, test_class_map)\n",
    "test_train_records, test_valid_records = test_parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RecordDataframeParser(parsers.Parser, parsers.FilepathMixin, parsers.SizeMixin, parsers.LabelsMixin):\n",
    "    def __init__(self, record_dataframe):\n",
    "        self.record_dataframe = record_dataframe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for group in self.record_dataframe.groupby(\"filepath\"):\n",
    "            yield group[1]\n",
    "    \n",
    "    def imageid(self, o):\n",
    "        return o.iloc[0][\"id\"]\n",
    "    \n",
    "    def filepath(self, o):\n",
    "        return o.iloc[0][\"filepath\"]\n",
    "    \n",
    "    def image_width_height(self, o):\n",
    "        width, height = o.iloc[0][\"width\"], o.iloc[0][\"height\"]\n",
    "        return (width, height)\n",
    "    \n",
    "    def labels(self, o):\n",
    "        return [annot[1][\"label_num\"] for annot in o.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BboxRecordDataframeParser(RecordDataframeParser, parsers.BBoxesMixin):\n",
    "    def bboxes(self, o):\n",
    "        return [BBox(annot[1][\"bbox_xmin\"], annot[1][\"bbox_ymin\"], annot[1][\"bbox_xmax\"], annot[1][\"bbox_ymax\"]) for annot in o.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MaskRecordDataframeParser(BboxRecordDataframeParser, parsers.MaskRCNN):\n",
    "    def iscrowds(self, o):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def masks(self, o):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RecordDataset(GenericDataset):\n",
    "    def __init__(self, records: Union[List[BaseRecord], ObservableList, str], class_map=None, name=None, description=None):\n",
    "        if isinstance(records, str):\n",
    "            self.load_from_file(records)\n",
    "        else:\n",
    "            self.records = records if isinstance(records, ObservableList) else ObservableList(records)\n",
    "            self.class_map = class_map\n",
    "        super().__init__(self.records, name=name, description=description)\n",
    "        self.records.register_callback(self.reset_infered_data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        base_string = \"\"\n",
    "        for col in self.stats_dataset.columns:\n",
    "            base_string += str(col) + \": \" + str(self.stats_dataset[col][0]) + \" | \"\n",
    "        base_string = base_string[:-2]\n",
    "        return base_string\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.records[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    \n",
    "    @property\n",
    "    def num_images(self):\n",
    "        return len(self)\n",
    "        \n",
    "    @classmethod\n",
    "    def load_from_record_dataframe(cls, record_data_df: pd.DataFrame, class_map=None, name=None, description=None):\n",
    "        records = cls.parse_df_to_records(record_data_df)\n",
    "        if class_map is None:\n",
    "            class_map = cls.create_class_map_from_record_df(record_data_df)\n",
    "        return cls(records, class_map=class_map, name=name, description=description)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_class_map_from_record_df(record_df):\n",
    "        sorted_labels = record_df[\"label\"].unique()[np.argsort(record_df[\"label_num\"].unique())].tolist()\n",
    "        sorted_label_nums = sorted(record_df[\"label_num\"].unique())\n",
    "        label_map = {key: value for key, value in zip(sorted_label_nums, sorted_labels)}\n",
    "        return ClassMap([label_map[i] if i in label_map.keys() else \"unknown_\"+str(i) for i in range(max(sorted_label_nums))])\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_df_to_records(record_data_df):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def load_from_file(self, path):\n",
    "        data = json.load(open(path))\n",
    "        df = pd.DataFrame(data[\"data\"])\n",
    "        records = self.parse_df_to_records(df)\n",
    "        self.records = ObservableList(records)\n",
    "        self.class_map = ClassMap(data[\"class_map\"])\n",
    "        self._name = data[\"name\"]\n",
    "        self._description = data[\"description\"]\n",
    "    \n",
    "    def save(self, save_path):\n",
    "        if not os.path.isdir(save_path):\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "        save_name = \"dataset\" if self.name == \"\" else self.name\n",
    "        if not os.path.isfile(os.path.join(save_path, save_name+\".json\")):\n",
    "            save_name = save_name+\".json\"\n",
    "        else:\n",
    "            counter = 1\n",
    "            while True:\n",
    "                save_name = save_name+\"(\"+str(counter)+\").json\"\n",
    "                if os.path.isfile(os.path.join(save_path, save_name)):\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        class_map = self.class_map if self.class_map is not None else self.create_class_map_from_record_df(df)\n",
    "        save_data = {\"name\": self.name, \"description\": self.description, \"data\": self.data.to_dict(), \"class_map\": class_map.id2class}\n",
    "        \n",
    "        json.dump(save_data, open(os.path.join(save_path, save_name), \"w\"), default=str)\n",
    "        \n",
    "    def get_image_by_index(self, index, width, height):\n",
    "        return draw_record_with_bokeh(self[index], width=None, height=height, return_figure=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def create_new_from_mask(cls, cls_instance, mask):\n",
    "        selection = cls_instance.data[mask]\n",
    "        filepaths = np.unique(selection[\"filepath\"]).tolist()\n",
    "        new_records = [record for record in cls_instance.records if str(record[\"filepath\"]) in filepaths]\n",
    "        return cls(new_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Aggregates stats from a list of records and returns a pandas dataframe with the aggregated stats. The creation time is not necessarily the real creation time. \n",
    "        This depends on the OS, for more information see: https://docs.python.org/3/library/os.html#os.stat_result.\"\"\"\n",
    "        data = []\n",
    "        for index,record in enumerate(obj.records):\n",
    "            for label, bbox in zip(record[\"labels\"], record[\"bboxes\"]):\n",
    "                file_stats = record[\"filepath\"].stat()\n",
    "                bbox_widht = bbox.xmax - bbox.xmin\n",
    "                bbox_height = bbox.ymax - bbox.ymin\n",
    "                area = bbox_widht * bbox_height\n",
    "                area_normalized = area / (record[\"width\"] * record[\"height\"])\n",
    "                bbox_ratio = bbox_widht / bbox_height\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"id\": record[\"imageid\"], \"width\": record[\"width\"], \"height\": record[\"height\"], \"label\": label, \n",
    "                        \"bbox_xmin\": bbox.xmin, \"bbox_xmax\": bbox.xmax, \"bbox_ymin\": bbox.ymin, \"bbox_ymax\": bbox.ymax, \"area\": area, \n",
    "                        \"area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"record_index\": index, \"bbox_width\": bbox_widht, \n",
    "                        \"bbox_height\": bbox_height, \"filepath\": str(record[\"filepath\"]), \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                        \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(record[\"bboxes\"])\n",
    "                    }\n",
    "                )\n",
    "        data = pd.DataFrame(data)\n",
    "        data[\"label_num\"] = data[\"label\"]\n",
    "        if obj.class_map is not None:\n",
    "            data[\"label\"] = data[\"label\"].apply(obj.class_map.get_id)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StatsDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        stats_dict = {}\n",
    "        stats_dict[\"no_imgs\"] = [obj.data[\"filepath\"].nunique()]\n",
    "        stats_dict[\"no_classes\"] = [obj.data[\"label\"].nunique()]\n",
    "        stats_dict[\"classes\"] = [list(obj.data[\"label\"].unique())]\n",
    "        stats_dict[\"area_min\"] = [obj.data[\"area\"].min()]\n",
    "        stats_dict[\"area_max\"] = [obj.data[\"area\"].max()]\n",
    "        stats_dict[\"num_annotations_min\"] = [obj.data[\"num_annotations\"].min()]\n",
    "        stats_dict[\"num_annotations_max\"] = [obj.data[\"num_annotations\"].max()]\n",
    "        stats_dict[\"name\"] = [obj._name]\n",
    "        stats_dict[\"description\"] = [obj._description]\n",
    "        return pd.DataFrame(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageStatsDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Creates a dataframe containing stats about the images.\"\"\"\n",
    "        stats_dict = {}\n",
    "        stats_dict[\"Num. imgs.\"] = obj.data[\"filepath\"].nunique()\n",
    "        stats_dict[\"Min Num. Objects\"] = obj.data[\"num_annotations\"].min()\n",
    "        stats_dict[\"Max Num. Objects\"] = obj.data[\"num_annotations\"].max()\n",
    "        stats_dict[\"Avg. Objects/Img\"] = round(obj.data[\"num_annotations\"].mean(),2)\n",
    "        df = pd.DataFrame.from_dict(stats_dict, orient=\"index\").T\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ClassStatsDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Creates a dataframe containing stats about the object classes.\"\"\"\n",
    "        stats_dict = {}\n",
    "        label_group = obj.data.groupby(\"label\")\n",
    "        for label, group in label_group:\n",
    "            label_stats = {}\n",
    "            label_stats[\"imgs\"] = group[\"filepath\"].nunique()\n",
    "            label_stats[\"objects\"] = group.shape[0]\n",
    "            label_stats[\"avg_objects_per_img\"] = label_stats[\"objects\"]/label_stats[\"imgs\"]\n",
    "            label_stats[\"frac_of_labels\"] = round(label_stats[\"objects\"]/obj.data.shape[0], 2)\n",
    "            stats_dict[label] = label_stats\n",
    "        df = pd.DataFrame(stats_dict).T\n",
    "        df = df.rename_axis('Class').reset_index()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GalleryStatsDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Creates a dataframe containing the data for a gallery.\"\"\"\n",
    "        df = obj.data[[\"id\", \"area\", \"num_annotations\", \"label\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"width\", \"height\"]].drop_duplicates().reset_index(drop=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BboxRecordDataset(RecordDataset):\n",
    "    data = DataDescriptorBbox()\n",
    "    gallery_data = GalleryStatsDescriptorBbox()\n",
    "    stats_dataset = StatsDescriptorBbox()\n",
    "    stats_image = ImageStatsDescriptorBbox()\n",
    "    stats_class = ClassStatsDescriptorBbox()\n",
    "    stats = StatsDescriptorBbox()\n",
    "    \n",
    "    def __init__(self, records: Union[List[BaseRecord], ObservableList, str], class_map=None, name=None, description=None):\n",
    "        super().__init__(records, class_map, name, description)\n",
    "        self.record_index_image_id_map = {str(record[\"filepath\"]): index for index, record in enumerate(self.records)}\n",
    "        self.data = None\n",
    "        self.gallery_data = None\n",
    "        self.stats_dataset = None\n",
    "        self.stats_image = None\n",
    "        self.stats_class = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_df_to_records(record_data_df):\n",
    "        return BboxRecordDataframeParser(record_data_df).parse(RandomSplitter([1]))[0]\n",
    "    \n",
    "    def get_image_by_image_id(self, image_id, width, height):\n",
    "        index = self.record_index_image_id_map[image_id]\n",
    "        return draw_record_with_bokeh(self[index], display_bbox=True, width=None, height=height, return_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_record_dataset = BboxRecordDataset(test_valid_records, test_class_map)\n",
    "assert isinstance(test_record_dataset.data, pd.DataFrame)\n",
    "assert isinstance(test_record_dataset.stats_dataset, pd.DataFrame)\n",
    "assert isinstance(test_record_dataset.stats_class, pd.DataFrame)\n",
    "assert isinstance(test_record_dataset.stats_image, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([False]*test_record_dataset.data.shape[0])\n",
    "mask[1] = True\n",
    "masked_test_record = test_record_dataset.create_new_from_mask(test_record_dataset, mask)\n",
    "assert len(masked_test_record) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection = cls_instance.data[mask]\n",
    "# filepaths = np.unique(selection[\"filepath\"])\n",
    "# new_records = [record for record in cls_instance.records if record[\"filepath\"] in filepaths]\n",
    "# return cls(new_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_old_record_dataset_stats = test_record_dataset.stats_dataset\n",
    "test_record_dataset.records.list = test_train_records\n",
    "test_new_record_dataset_stats = test_record_dataset.stats_dataset\n",
    "assert all(test_old_record_dataset_stats != test_new_record_dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_record_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_regenerated_record_dataset = BboxRecordDataset.load_from_record_dataframe(test_record_dataset.data)\n",
    "assert len(test_regenerated_record_dataset.records) == len(test_record_dataset.records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"dump_dir\", ignore_errors=True)\n",
    "os.mkdir(\"dump_dir\")\n",
    "test_record_dataset.name = \"\"\n",
    "test_record_dataset.save(\"dump_dir\")\n",
    "test_record_dataset.save(\"dump_dir\")\n",
    "assert len(os.listdir(\"dump_dir\")) == 2\n",
    "assert os.path.isfile(\"dump_dir/dataset.json\")\n",
    "test_loaded_record_dataset = BboxRecordDataset(\"dump_dir/dataset.json\")\n",
    "assert test_record_dataset.data.sort_values(\"area\").shape == test_loaded_record_dataset.data.sort_values(\"id\").shape\n",
    "shutil.rmtree(\"dump_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports\n",
    "# from icevision.all import *\n",
    "# import icedata\n",
    "\n",
    "# # Load the Fridge dataset\n",
    "# path = icedata.fridge.load_data()\n",
    "\n",
    "# # Get the class_map, a utility that maps from number IDs to classs names\n",
    "# class_map = icedata.fridge.class_map()\n",
    "\n",
    "# # Fridge parser: provided out-of-the-box\n",
    "# parser = icedata.fridge.parser(data_dir=path, class_map=class_map)\n",
    "# train_records, valid_records = parser.parse()\n",
    "\n",
    "# # shows images with corresponding labels and boxes\n",
    "# # show_records(train_records[:6], ncols=3, class_map=class_map, show=True)\n",
    "\n",
    "# # Define transforms - using Albumentations transforms out of the box\n",
    "# train_tfms = tfms.A.Adapter(\n",
    "#     [*tfms.A.aug_tfms(size=384, presize=512), tfms.A.Normalize()]\n",
    "# )\n",
    "# valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(384), tfms.A.Normalize()])\n",
    "# # Create both training and validation datasets\n",
    "# train_ds = Dataset(train_records, train_tfms)\n",
    "# valid_ds = Dataset(valid_records, valid_tfms)\n",
    "\n",
    "# # Create both training and validation dataloaders\n",
    "# train_dl = faster_rcnn.train_dl(train_ds, batch_size=14, num_workers=4, shuffle=True)\n",
    "# valid_dl = faster_rcnn.valid_dl(valid_ds, batch_size=14, num_workers=4, shuffle=False)\n",
    "\n",
    "# # Create model\n",
    "# model = faster_rcnn.model(num_classes=len(class_map))\n",
    "\n",
    "# # Define metrics\n",
    "# metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]\n",
    "\n",
    "# # Train using fastai2\n",
    "# learn = faster_rcnn.fastai.learner(\n",
    "#     dls=[train_dl, valid_dl], model=model, metrics=metrics\n",
    "# )\n",
    "\n",
    "# learn.fine_tune(20, lr=1e-4)\n",
    "\n",
    "\n",
    "# new_train_ds = Dataset(train_records, valid_tfms)\n",
    "# samples_plus_losses, preds, losses_stats = faster_rcnn.interp.plot_top_losses(model=model, dataset=new_train_ds, sort_by=\"loss_total\", n_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from icevision.all import *\n",
    "import icedata\n",
    "\n",
    "# Load the Pets dataset\n",
    "path = icedata.pets.load_data()\n",
    "\n",
    "# Get the class_map, a utility that maps from number IDs to classs names\n",
    "class_map = icedata.pets.class_map()\n",
    "\n",
    "# Pets parser: provided out-of-the-box\n",
    "parser = icedata.pets.parser(data_dir=path, class_map=class_map)\n",
    "train_records, valid_records = parser.parse()\n",
    "\n",
    "# shows images with corresponding labels and boxes\n",
    "# show_records(train_records[:6], ncols=3, class_map=class_map, show=True)\n",
    "\n",
    "# Define transforms - using Albumentations transforms out of the box\n",
    "train_tfms = tfms.A.Adapter(\n",
    "    [*tfms.A.aug_tfms(size=384, presize=512), tfms.A.Normalize()]\n",
    ")\n",
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(384), tfms.A.Normalize()])\n",
    "# Create both training and validation datasets\n",
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)\n",
    "\n",
    "# Create both training and validation dataloaders\n",
    "train_dl = faster_rcnn.train_dl(train_ds, batch_size=10, num_workers=4, shuffle=True)\n",
    "valid_dl = faster_rcnn.valid_dl(valid_ds, batch_size=10, num_workers=4, shuffle=False)\n",
    "\n",
    "# Create model\n",
    "model = faster_rcnn.model(num_classes=len(class_map))\n",
    "\n",
    "# Define metrics\n",
    "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]\n",
    "\n",
    "# Train using fastai2\n",
    "learn = faster_rcnn.fastai.learner(\n",
    "    dls=[train_dl, valid_dl], model=model, metrics=metrics\n",
    ")\n",
    "\n",
    "learn.fine_tune(5, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_ds = Dataset(train_records, valid_tfms)\n",
    "samples_plus_losses, preds, losses_stats = faster_rcnn.interp.plot_top_losses(model=model, dataset=new_train_ds, sort_by=\"loss_total\", n_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MetricBaseDataObjectDetection(DatasetDescriptor):\n",
    "    \"\"\"Calculates TP, FP, FN at the given ious. Requires the Dataset to have DataDescriptorBboxWithPredictions as the descriptor Data\"\"\"\n",
    "    def __init__(self, data_descriptor_name=\"base_data\", image_identification_col=\"filepath\", ious=None):\n",
    "        self.image_identification_col = image_identification_col\n",
    "        self.data_descriptor_name = data_descriptor_name\n",
    "        if ious is None:\n",
    "            self.ious = np.arange(0.5, 1, 0.05).round(2)\n",
    "        else:\n",
    "            self.ious = ious\n",
    "        \n",
    "    def calculate_description(self, obj):\n",
    "        data_list = []\n",
    "        iou_bar = master_bar(self.ious, total=len(self.ious))\n",
    "        iou_bar.main_bar.comment = f\"iou: {self.ious[0]}\"\n",
    "        for index,iou in enumerate(iou_bar):\n",
    "            iou_bar.main_bar.comment = f\"iou: {self.ious[min(index+1, len(self.ious)-1)]}\"\n",
    "            data = getattr(obj, self.data_descriptor_name)\n",
    "            data = data.copy()\n",
    "            data[\"statistic\"] = \"FP\"\n",
    "            data.loc[data[\"is_prediction\"] == False, \"statistic\"] = \"FN\"\n",
    "            data[\"iou\"] = iou\n",
    "            for image_path, image_data in progress_bar(data.groupby(self.image_identification_col), parent=iou_bar):\n",
    "                predictions = image_data[image_data[\"is_prediction\"] == True]\n",
    "                annotations = image_data[image_data[\"is_prediction\"] == False]\n",
    "                for index, annotation in annotations.iterrows():\n",
    "                    x_overlap = np.maximum(predictions[\"bbox_xmax\"]*0, np.minimum(predictions[\"bbox_xmax\"], annotation[\"bbox_xmax\"]) - np.maximum(predictions[\"bbox_xmin\"], annotation[\"bbox_xmin\"]))\n",
    "                    y_overlap = np.maximum(predictions[\"bbox_xmax\"]*0, np.minimum(predictions[\"bbox_ymax\"], annotation[\"bbox_ymax\"]) - np.maximum(predictions[\"bbox_ymin\"], annotation[\"bbox_ymin\"]))\n",
    "                    intersections = x_overlap * y_overlap\n",
    "                    ious = intersections / (predictions[\"area\"] + annotation[\"area\"] - intersections)\n",
    "                    if any(np.logical_and(ious >= iou, predictions[\"label\"] == annotation[\"label\"])):\n",
    "                        index_position = np.argmax(ious)\n",
    "                        data.loc[index, \"statistic\"] = None\n",
    "                        data.loc[predictions.index[index_position], \"statistic\"] = \"TP\"\n",
    "                        # remove the annotation to avoid double counting\n",
    "                        predictions = predictions.drop(index=predictions.index[index_position])\n",
    "            data_list.append(data)\n",
    "        return pd.concat(data_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PrecisionRecallMetricsObjectDetection(DatasetDescriptor):\n",
    "    def __init__(self, ious=None):\n",
    "        if ious is None:\n",
    "            self.ious = np.arange(0.5, 1, 0.05).round(2)\n",
    "        else:\n",
    "            self.ious = ious\n",
    "            \n",
    "    def calculate_description(self, obj):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionResultsDataset(GenericDataset):\n",
    "    \n",
    "    def __init__(self, dataframe, name=None, description=None):\n",
    "        super().__init__(dataframe, name, description)        \n",
    "\n",
    "    def save(self, path):\n",
    "        if not os.path.exists(os.path.join(*path.split(\"/\")[:-1])):\n",
    "            os.makedirs(os.path.join(*path.split(\"/\")[:-1]))\n",
    "        self.base_data.to_csv(path)\n",
    "        \n",
    "    def get_image_by_image_id(self, image_id, width=None, height=None):\n",
    "        df_pred = self.base_data[(self.base_data[\"filepath\"] == image_id) & (self.base_data[\"is_prediction\"] == True)]\n",
    "        df_gt = self.base_data[(self.base_data[\"filepath\"] == image_id) & (self.base_data[\"is_prediction\"] == False)]\n",
    "        \n",
    "        parser_pred = BboxRecordDataframeParser(df_pred)\n",
    "        parser_gt = BboxRecordDataframeParser(df_gt)\n",
    "        res_gt = parser_gt.parse(show_pbar=False, autofix=False)[1][0]\n",
    "        res_pred = parser_pred.parse(show_pbar=False, autofix=False)[1]\n",
    "        if len(res_pred) == 0:\n",
    "            res_pred = deepcopy(res_gt)\n",
    "            res_pred[\"labels\"] = []\n",
    "            res_pred[\"bboxes\"] = []\n",
    "        else:\n",
    "            res_pred = res_pred[0]\n",
    "        plot_gt = draw_record_with_bokeh(res_gt, display_bbox=True, return_figure=True, width=width, height=height)\n",
    "        plot_pred = draw_record_with_bokeh(res_pred, display_bbox=True, return_figure=True, width=width, height=height)\n",
    "        return pn.Row(pn.Column(pn.Row(\"<b>Ground Truth</b>\",  align=\"center\"), plot_gt), pn.Column(pn.Row(\"<b>Prediction</b>\",  align=\"center\"), plot_pred))\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        df = pd.read_csv(path)\n",
    "        return cls(df, None, None)\n",
    "        \n",
    "    @classmethod\n",
    "    def init_from_preds_and_sampels(cls, predictions, sampels_plus_losses, padded_along_shortest=True, class_map=None, name=None, description=None):\n",
    "        \"\"\"The input_records are required because they are the only information source with the image stats(width, etc.) for the image on the disk.\"\"\"\n",
    "        data = []\n",
    "        for index, (prediction, sampel_plus_loss) in enumerate(zip(predictions, samples_plus_losses)):\n",
    "            # TODO: At the moment only resize_and_pad or resize are handelt. Check if there are other edge cases that need to be included\n",
    "            # The correction requires that the sampel_plus_loss has the scaled image sizes (not the padded ones or the original ones)\n",
    "            # correct the width and height to the values of the original image\n",
    "            img = Image.open(sampel_plus_loss[\"filepath\"])\n",
    "            width = img.size[0]\n",
    "            height = img.size[1]\n",
    "            # use bool to int for padded_along_shortest and int(sampel_plus_loss[\"width\"] < sampel_plus_loss[\"height\"]) to avoid if branches\n",
    "            factor = max(width, height)/max(sampel_plus_loss[\"width\"], sampel_plus_loss[\"height\"])\n",
    "            padding = max(sampel_plus_loss[\"width\"], sampel_plus_loss[\"height\"]) - min(sampel_plus_loss[\"width\"], sampel_plus_loss[\"height\"])\n",
    "            # at the end /2 due to symmetric padding\n",
    "            correct_x = lambda x: factor * (x - int(padded_along_shortest) * int(sampel_plus_loss[\"width\"] < sampel_plus_loss[\"height\"]) * padding/2)\n",
    "            correct_y = lambda y: factor * (y - int(padded_along_shortest) * int(sampel_plus_loss[\"width\"] > sampel_plus_loss[\"height\"]) * padding/2)\n",
    "            for label, bbox, score in zip(prediction[\"labels\"], prediction[\"bboxes\"], prediction[\"scores\"]):\n",
    "                xmin, xmax, ymin, ymax = correct_x(bbox.xmin), correct_x(bbox.xmax), correct_y(bbox.ymin), correct_y(bbox.ymax)\n",
    "                file_stats = sampel_plus_loss[\"filepath\"].stat()\n",
    "                bbox_widht = xmax - xmin\n",
    "                bbox_height = ymax - ymin\n",
    "                area = bbox_widht * bbox_height\n",
    "                area_normalized = area / (width * height)\n",
    "                bbox_ratio = bbox_widht / bbox_height\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"id\": sampel_plus_loss[\"imageid\"], \"width\": width, \"height\": height, \"label\": label,\n",
    "                        \"score\": score, \"bbox_xmin\": xmin, \"bbox_xmax\": xmax, \"bbox_ymin\": ymin, \"bbox_ymax\": ymax, \"area\": area, \n",
    "                        \"area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"record_index\": index, \"bbox_width\": bbox_widht, \n",
    "                        \"bbox_height\": bbox_height, \"filepath\": str(sampel_plus_loss[\"filepath\"]), \"filename\": str(sampel_plus_loss[\"filepath\"]).split(\"/\")[-1], \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                        \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(prediction[\"bboxes\"]), \"is_prediction\": True,\n",
    "                        \"loss_classifier\": sampel_plus_loss[\"loss_classifier\"], \"loss_box_reg\": sampel_plus_loss[\"loss_box_reg\"], \"loss_objectness\": sampel_plus_loss[\"loss_objectness\"],\n",
    "                        \"loss_rpn_box_reg\": sampel_plus_loss[\"loss_rpn_box_reg\"], \"loss_total\": sampel_plus_loss[\"loss_total\"]\n",
    "                    }\n",
    "                )\n",
    "            for label, bbox in zip(sampel_plus_loss[\"labels\"], sampel_plus_loss[\"bboxes\"]):\n",
    "                xmin, xmax, ymin, ymax = correct_x(bbox.xmin), correct_x(bbox.xmax), correct_y(bbox.ymin), correct_y(bbox.ymax)\n",
    "                file_stats = sampel_plus_loss[\"filepath\"].stat()\n",
    "                bbox_widht = xmax - xmin\n",
    "                bbox_height = ymax - ymin\n",
    "                area = bbox_widht * bbox_height\n",
    "                area_normalized = area / (width * height)\n",
    "                bbox_ratio = bbox_widht / bbox_height\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"id\": sampel_plus_loss[\"imageid\"], \"width\": width, \"height\": height, \"label\": label,\n",
    "                        \"score\": 1, \"bbox_xmin\": xmin, \"bbox_xmax\": xmax, \"bbox_ymin\": ymin, \"bbox_ymax\": ymax, \"area\": area, \n",
    "                        \"area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"record_index\": index, \"bbox_width\": bbox_widht, \n",
    "                        \"bbox_height\": bbox_height, \"filepath\": str(sampel_plus_loss[\"filepath\"]), \"filename\": str(sampel_plus_loss[\"filepath\"]).split(\"/\")[-1], \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                        \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(prediction[\"bboxes\"]), \"is_prediction\": False,\n",
    "                        \"loss_classifier\": sampel_plus_loss[\"loss_classifier\"], \"loss_box_reg\": sampel_plus_loss[\"loss_box_reg\"], \"loss_objectness\": sampel_plus_loss[\"loss_objectness\"],\n",
    "                        \"loss_rpn_box_reg\": sampel_plus_loss[\"loss_rpn_box_reg\"], \"loss_total\": sampel_plus_loss[\"loss_total\"]\n",
    "                    }\n",
    "                )\n",
    "        data = pd.DataFrame(data)\n",
    "        data[\"label_num\"] = data[\"label\"]\n",
    "        if class_map is not None:\n",
    "            data[\"label\"] = data[\"label\"].apply(class_map.get_id)\n",
    "        \n",
    "        return cls(data, name, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odrd = ObjectDetectionResultsDataset.init_from_preds_and_sampels(preds, samples_plus_losses, class_map=class_map)\n",
    "# odrd.save(\"test_results/pets_train.dat\")\n",
    "odrd = ObjectDetectionResultsDataset.load(\"test_results/pets_train.dat\")\n",
    "# odrd.base_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from icevision.all import *\n",
    "import icedata\n",
    "\n",
    "# Load the Pets dataset\n",
    "path = icedata.pets.load_data()\n",
    "\n",
    "# Get the class_map, a utility that maps from number IDs to classs names\n",
    "class_map = icedata.pets.class_map()\n",
    "\n",
    "# Pets parser: provided out-of-the-box\n",
    "parser = icedata.pets.parser(data_dir=path, class_map=class_map)\n",
    "train_records, valid_records = parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in train_records if i[\"filepath\"] == \"/home/frederik/.icevision/data/pets/images/basset_hound_182.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_record_with_bokeh(train_records[0], display_bbox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (metric_base_dataath, iou), data in progress_bar(odrd.metric_base_data.groupby([\"filepath\", \"iou\"]), comment=\"Calculating precision and recall\"):\n",
    "#     tp = (data[\"statistic\"] == \"TP\").sum()\n",
    "#     fp = (data[\"statistic\"] == \"FP\").sum()\n",
    "#     fn = (data[\"statistic\"] == \"FN\").sum()\n",
    "#     precision = tp/(tp+fp) if tp+fp > 0 else 0\n",
    "#     recall = tp/(tp+fn) if tp+fn > 0 else 0\n",
    "#     odrd.metric_base_data.loc[data.index,\"img_tp\"] = tp\n",
    "#     odrd.metric_base_data.loc[data.index,\"img_fp\"] = fp\n",
    "#     odrd.metric_base_data.loc[data.index,\"img_fn\"] = fn\n",
    "#     odrd.metric_base_data.loc[data.index,\"precision\"] = precision\n",
    "#     odrd.metric_base_data.loc[data.index,\"recall\"] = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
