{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "> Provides dataset for icevision records and classmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import datetime\n",
    "from typing import Union, Optional, List\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from random import shuffle\n",
    "from abc import ABC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import panel as pn\n",
    "\n",
    "import icevision\n",
    "from icevision.core.record import BaseRecord\n",
    "from icevision.core.record_defaults import ObjectDetectionRecord, InstanceSegmentationRecord\n",
    "import icevision.parsers as parsers\n",
    "from icevision.data.data_splitter import SingleSplitSplitter\n",
    "from icevision.core.bbox import BBox\n",
    "from icevision.core.mask import EncodedRLEs, MaskArray\n",
    "from icevision.core.class_map import ClassMap\n",
    "\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from icevision_dashboards.plotting.utils import draw_record_with_bokeh\n",
    "from icevision_dashboards.metrics import APObjectDetection, APInstanceSegmentation\n",
    "from icevision_dashboards.core.data import *\n",
    "from icevision_dashboards.utils import erles_to_counts_to_utf8, erles_to_string, string_to_erles, correct_mask, decorrect_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from icevision.core.record_components import FilepathRecordComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icedata\n",
    "import pickle\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_data_dir = icedata.fridge.load_data()\n",
    "test_object_detection_class_map = icedata.fridge.class_map()\n",
    "test_object_detection_parser = icedata.fridge.parser(test_object_detection_data_dir)\n",
    "test_object_detection_train_records, test_object_detection_valid_records = test_object_detection_parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_data_path = icedata.pennfudan.load_data()\n",
    "test_instance_segmentation_parser = icedata.pennfudan.parser(data_dir=test_instance_segmentation_data_path)\n",
    "test_instance_segmentation_train_records, test_instance_segmentation_valid_records = test_instance_segmentation_parser.parse()\n",
    "test_instance_segmentation_class_map = test_instance_segmentation_train_records[0].detection.class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RecordDataframeParser(parsers.Parser):\n",
    "    \"\"\"IceVision parser for pandas dataframes. This parser is mostly used by the RecordDataset to load records from a saved RecordDataset.\"\"\"\n",
    "    def __init__(self, record_template):\n",
    "        super().__init__(record_template)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for group in self.record_dataframe.groupby(\"filepath\"):\n",
    "            yield group[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.record_dataframe[\"filepath\"].nunique\n",
    "    \n",
    "    def record_id(self, o):\n",
    "        return o.iloc[0][\"id\"]\n",
    "\n",
    "    def parse_fields(self, o, record, is_new):\n",
    "        width, height = o.iloc[0][\"width\"], o.iloc[0][\"height\"]\n",
    "        record.set_filepath(o.iloc[0][\"filepath\"])\n",
    "        record.set_img_size((width, height))\n",
    "        record.detection.set_class_map(self.class_map)\n",
    "        record.detection.add_labels(o[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RecordDataset(GenericDataset, ABC):\n",
    "    \"\"\"Base class dashboard datasets that are based on IceVision records.\"\"\"\n",
    "    def __init__(self, records: Union[List[BaseRecord], ObservableList, str], class_map, name=None, description=None):\n",
    "        if isinstance(records, str):\n",
    "            self.load_from_file(records)\n",
    "        else:\n",
    "            if isinstance(records, icevision.data.record_collection.RecordCollection):\n",
    "                records = records._records._list\n",
    "            self.records = records if isinstance(records, ObservableList) else ObservableList(records)\n",
    "            self.class_map = class_map\n",
    "        super().__init__(self.records, name=name, description=description)\n",
    "        self.records.register_callback(self.reset_infered_data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        base_string = \"\"\n",
    "        if getattr(self, \"stats_dataset\", None) is not None: \n",
    "            for col in self.stats_dataset.columns:\n",
    "                base_string += str(col) + \": \" + str(self.stats_dataset[col][0]) + \" | \"\n",
    "            base_string = base_string[:-2]\n",
    "        return base_string\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.records[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        \"\"\"Add two RecordDatases together but sets name and description to None for the new RecordDataset.\"\"\"\n",
    "        if sorted(self.class_map._id2class) != sorted(other.class_map._id2class):\n",
    "            raise ValueError(\"The two RecordDatasets don't have the same class_map\")\n",
    "        else:\n",
    "            return RecordDataset(self.records+other.records, class_map=self.class_map)\n",
    "    \n",
    "    def split_in_train_and_val(self, train_fraction):\n",
    "        records = list(self.records)\n",
    "        indices = list(range(len(records)))\n",
    "        shuffle(indices)\n",
    "        if train_fraction > 1:\n",
    "            train_fraction /= len(records)\n",
    "        train = [records[index] for index in indices[:int(len(records)*train_fraction)]]\n",
    "        val = [records[index] for index in indices[int(len(records)*train_fraction):]]\n",
    "        return train, val\n",
    "    \n",
    "    @property\n",
    "    def num_images(self):\n",
    "        return len(self)\n",
    "        \n",
    "    @classmethod\n",
    "    def load_from_record_dataframe(cls, record_data_df: pd.DataFrame, class_map=None, name=None, description=None):\n",
    "        if class_map is None:\n",
    "            class_map = ClassMap(json.loads(record_data_df[\"class_map\"].values[0])[1:])\n",
    "        records = cls.parse_df_to_records(record_data_df, class_map)\n",
    "        return cls(records, class_map=class_map, name=name, description=description)\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_df_to_records(record_data_df):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def load_from_file(self, path):\n",
    "        data = json.load(open(path))\n",
    "        df = pd.DataFrame(data[\"data\"])\n",
    "        self.class_map = ClassMap(data[\"class_map\"])\n",
    "        self._name = data[\"name\"]\n",
    "        self._description = data[\"description\"]\n",
    "        records = self.parse_df_to_records(df, self.class_map)\n",
    "        self.records = ObservableList(records)\n",
    "    \n",
    "    def save(self, save_path):\n",
    "        if not os.path.isdir(save_path):\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "        save_name = \"dataset\" if self.name == \"\" or self.name is None else self.name\n",
    "        if not os.path.isfile(os.path.join(save_path, save_name+\".json\")):\n",
    "            save_name = save_name+\".json\"\n",
    "        else:\n",
    "            counter = 1\n",
    "            while True:\n",
    "                save_name = save_name+\"(\"+str(counter)+\").json\"\n",
    "                if os.path.isfile(os.path.join(save_path, save_name)):\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        class_map = self.class_map if self.class_map is not None else self.create_class_map_from_record_df(self.data)\n",
    "        save_data = {\"name\": self.name, \"description\": self.description, \"data\": self.data.to_dict(), \"class_map\": class_map._id2class}\n",
    "        \n",
    "        json.dump(save_data, open(os.path.join(save_path, save_name), \"w\"), default=str)\n",
    "        \n",
    "    def get_image_by_index(self, index, width, height):\n",
    "        return draw_record_with_bokeh(self[index], class_map=self.class_map, width=None, height=height, return_figure=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def create_new_from_mask(cls, cls_instance, mask):\n",
    "        selection = cls_instance.data[mask]\n",
    "        filepaths = np.unique(selection[\"filepath\"]).tolist()\n",
    "        new_records = [record for record in cls_instance.records if str(record.filepath) in filepaths]\n",
    "        return cls(new_records, cls_instance.class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResultsDataset(GenericDataset):\n",
    "    \"\"\"Dashboard dataset for the results of and object detection system.\"\"\"\n",
    "    metric_data_ap = None\n",
    "    df_parser = None\n",
    "    \n",
    "    def __init__(self, dataframe, name=None, description=None):\n",
    "        super().__init__(dataframe, name, description)\n",
    "        # instanciate metric data and preload it\n",
    "        self.metric_data_ap = None\n",
    "        self.class_map = ClassMap([str(i) for i in self.base_data[[\"label\", \"label_num\"]].drop_duplicates().sort_values(\"label_num\")[\"label\"].tolist()])\n",
    "\n",
    "    def save(self, path):\n",
    "        if not os.path.exists(os.path.join(*path.split(\"/\")[:-1])):\n",
    "            os.makedirs(os.path.join(*path.split(\"/\")[:-1]))\n",
    "        self.base_data.to_csv(path)\n",
    "        \n",
    "    def get_image_by_image_id(self, image_id, width=None, height=None):\n",
    "        \"\"\"For gallery dashboards\"\"\"\n",
    "        df_pred = self.base_data[(self.base_data[\"filepath\"] == image_id) & (self.base_data[\"is_prediction\"] == True)]\n",
    "        df_gt = self.base_data[(self.base_data[\"filepath\"] == image_id) & (self.base_data[\"is_prediction\"] == False)]\n",
    "        \n",
    "        parser_pred = self.df_parser(df_pred, self.class_map)\n",
    "        parser_gt = self.df_parser(df_gt, self.class_map)\n",
    "        res_gt = parser_gt.parse(show_pbar=False, autofix=False)[1][0]\n",
    "        res_pred = parser_pred.parse(show_pbar=False, autofix=False)[1]\n",
    "        if len(res_pred) == 0:\n",
    "            res_pred = deepcopy(res_gt)\n",
    "            res_pred.labels = []\n",
    "            res_pred.bboxes = []\n",
    "        else:\n",
    "            res_pred = res_pred[0]\n",
    "        plot_gt = draw_record_with_bokeh(res_gt, display_bbox=True, display_mask=True, return_figure=True, width=width, height=height)\n",
    "        plot_pred = draw_record_with_bokeh(res_pred, display_bbox=True, display_mask=True, return_figure=True, width=width, height=height)\n",
    "        return pn.Row(pn.Column(pn.Row(\"<b>Ground Truth</b>\",  align=\"center\"), plot_gt), pn.Column(pn.Row(\"<b>Prediction</b>\",  align=\"center\"), plot_pred))\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        df = pd.read_csv(path)\n",
    "        return cls(df, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BboxRecordDataframeParser(RecordDataframeParser):\n",
    "    \"\"\"Extends the RecordDataframeParser for object detection\"\"\"\n",
    "    def __init__(self, record_dataframe, class_map):\n",
    "        super().__init__(ObjectDetectionRecord())\n",
    "        self.record_dataframe = record_dataframe\n",
    "        self.class_map = class_map\n",
    "    \n",
    "    def parse_fields(self, o, record, is_new):\n",
    "        super().parse_fields(o, record, is_new)\n",
    "        record.detection.add_bboxes([BBox(annot[1][\"bbox_xmin\"], annot[1][\"bbox_ymin\"], annot[1][\"bbox_xmax\"], annot[1][\"bbox_ymax\"]) for annot in o.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataDescriptorBbox(DatasetDescriptor):\n",
    "    \"\"\"Dashboard dataset for object detection\"\"\"\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Aggregates stats from a list of records and returns a pandas dataframe with the aggregated stats. The creation time is not necessarily the real creation time. \n",
    "        This depends on the OS, for more information see: https://docs.python.org/3/library/os.html#os.stat_result.\"\"\"\n",
    "        data = []\n",
    "        for index,record in enumerate(obj.records):\n",
    "            record_commons, record_detections = record.as_dict()[\"common\"], record.aggregate_objects()[\"detection\"]\n",
    "            for label, bbox in zip(record_detections[\"labels\"], record_detections[\"bboxes\"]):\n",
    "                file_stats = record.filepath.stat()\n",
    "                bbox_width = bbox[\"bbox_width\"]\n",
    "                bbox_height = bbox[\"bbox_height\"]\n",
    "                area = bbox_width*bbox_height\n",
    "                area_normalized = area / (record.width * record.height)\n",
    "                bbox_ratio = bbox_width / bbox_height\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"id\": record_commons[\"record_id\"], \"width\": record.width, \"height\": record.height, \"label\": label, \"area_square_root\": bbox[\"bbox_sqrt_area\"], \"area_square_root_normalized\": area_normalized**0.5,\n",
    "                        \"bbox_xmin\": bbox[\"bbox_x\"], \"bbox_xmax\": bbox[\"bbox_x\"]+bbox[\"bbox_width\"], \"bbox_ymin\": bbox[\"bbox_y\"], \"bbox_ymax\": bbox[\"bbox_y\"]+bbox[\"bbox_height\"], \n",
    "                        \"bbox_xmin_normalized\": bbox[\"bbox_x\"]/record.width, \"bbox_xmax_normalized\": (bbox[\"bbox_x\"]+bbox[\"bbox_width\"])/record.width, \"bbox_ymin_normalized\": bbox[\"bbox_y\"]/record.height,\n",
    "                        \"bbox_ymax_normalized\": (bbox[\"bbox_y\"]+bbox[\"bbox_height\"])/record.height, \"area\": area, \"area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"bbox_ratio_normalized\": bbox_ratio*(record.height/record.width),\n",
    "                        \"record_index\": index, \"bbox_width\": bbox_width, \"bbox_height\": bbox_height, \"bbox_width_normalized\": bbox_width/record.width, \"bbox_height_normalized\": bbox_height/record.height, \n",
    "                        \"filepath\": str(record.filepath), \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \"class_map\": json.dumps(record.detection.class_map._id2class),\n",
    "                        \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(record_detections[\"bboxes\"])\n",
    "                    }\n",
    "                )\n",
    "        data = pd.DataFrame(data)\n",
    "        data[\"label_num\"] = data[\"label\"]\n",
    "        if obj.class_map is not None:\n",
    "            data[\"label\"] = data[\"label\"].apply(obj.class_map.get_by_id)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StatsDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        stats_dict = {}\n",
    "        stats_dict[\"no_imgs\"] = [obj.data[\"filepath\"].nunique()]\n",
    "        stats_dict[\"no_classes\"] = [obj.data[\"label\"].nunique()]\n",
    "        stats_dict[\"classes\"] = [list(obj.data[\"label\"].unique())]\n",
    "        stats_dict[\"area_min\"] = [obj.data[\"area\"].min()]\n",
    "        stats_dict[\"area_max\"] = [obj.data[\"area\"].max()]\n",
    "        stats_dict[\"num_annotations_min\"] = [obj.data[\"num_annotations\"].min()]\n",
    "        stats_dict[\"num_annotations_max\"] = [obj.data[\"num_annotations\"].max()]\n",
    "        stats_dict[\"name\"] = [obj._name]\n",
    "        stats_dict[\"description\"] = [obj._description]\n",
    "        return pd.DataFrame(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageStatsDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Creates a dataframe containing stats about the images.\"\"\"\n",
    "        stats_dict = {}\n",
    "        stats_dict[\"Num. imgs.\"] = obj.data[\"filepath\"].nunique()\n",
    "        stats_dict[\"Min Num. Objects\"] = obj.data[\"num_annotations\"].min()\n",
    "        stats_dict[\"Max Num. Objects\"] = obj.data[\"num_annotations\"].max()\n",
    "        stats_dict[\"Avg. Objects/Img\"] = round(obj.data[\"num_annotations\"].mean(),2)\n",
    "        df = pd.DataFrame.from_dict(stats_dict, orient=\"index\").T\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ClassStatsDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Creates a dataframe containing stats about the object classes.\"\"\"\n",
    "        stats_dict = {}\n",
    "        label_group = obj.data.groupby(\"label\")\n",
    "        for label, group in label_group:\n",
    "            label_stats = {}\n",
    "            label_stats[\"imgs\"] = group[\"filepath\"].nunique()\n",
    "            label_stats[\"objects\"] = group.shape[0]\n",
    "            label_stats[\"avg_objects_per_img\"] = label_stats[\"objects\"]/label_stats[\"imgs\"]\n",
    "            label_stats[\"frac_of_labels\"] = round(label_stats[\"objects\"]/obj.data.shape[0], 2)\n",
    "            stats_dict[label] = label_stats\n",
    "        df = pd.DataFrame(stats_dict).T\n",
    "        df = df.rename_axis('Class').reset_index()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GalleryStatsDescriptorBbox(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Creates a dataframe containing the data for a gallery.\"\"\"\n",
    "        df = obj.data[[\"id\", \"area\", \"num_annotations\", \"label\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"width\", \"height\"]].drop_duplicates().reset_index(drop=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BboxRecordDataset(RecordDataset):\n",
    "    data = DataDescriptorBbox()\n",
    "    gallery_data = GalleryStatsDescriptorBbox()\n",
    "    stats_dataset = StatsDescriptorBbox()\n",
    "    stats_image = ImageStatsDescriptorBbox()\n",
    "    stats_class = ClassStatsDescriptorBbox()\n",
    "    stats = StatsDescriptorBbox()\n",
    "    \n",
    "    def __init__(self, records: Union[List[BaseRecord], ObservableList, str], class_map=None, name=None, description=None):\n",
    "        super().__init__(records, class_map, name, description)\n",
    "        self.record_index_image_id_map = {str(record.filepath): index for index, record in enumerate(self.records)}\n",
    "        self.data = None\n",
    "        self.gallery_data = None\n",
    "        self.stats_dataset = None\n",
    "        self.stats_image = None\n",
    "        self.stats_class = None\n",
    "        self.stats = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_df_to_records(record_data_df, class_map):\n",
    "        return BboxRecordDataframeParser(record_data_df, class_map).parse(SingleSplitSplitter())[0]\n",
    "    \n",
    "    def get_image_by_image_id(self, image_id, width, height):\n",
    "        index = self.record_index_image_id_map[image_id]\n",
    "        return draw_record_with_bokeh(self[index], display_bbox=True, display_mask=True, class_map=self.class_map, width=None, height=height, return_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_record_dataset = BboxRecordDataset(test_object_detection_valid_records, test_object_detection_class_map)\n",
    "assert isinstance(test_object_detection_record_dataset.data, pd.DataFrame)\n",
    "assert isinstance(test_object_detection_record_dataset.stats_dataset, pd.DataFrame)\n",
    "assert isinstance(test_object_detection_record_dataset.stats_class, pd.DataFrame)\n",
    "assert isinstance(test_object_detection_record_dataset.stats_image, pd.DataFrame)\n",
    "assert isinstance(test_object_detection_record_dataset.stats, pd.DataFrame)\n",
    "\n",
    "assert isinstance(test_object_detection_record_dataset.__repr__(), str)\n",
    "test_object_detection_split_train_records, test_object_detection_split_valid_records = test_object_detection_record_dataset.split_in_train_and_val(0.8)\n",
    "assert len(test_object_detection_record_dataset.base_data) == len(test_object_detection_split_train_records) + len(test_object_detection_split_valid_records)\n",
    "assert test_object_detection_record_dataset.num_images == 26\n",
    "\n",
    "test_object_detection_added_record_dataset = test_object_detection_record_dataset + test_object_detection_record_dataset\n",
    "assert len(test_object_detection_added_record_dataset) == len(test_object_detection_record_dataset)*2\n",
    "assert test_object_detection_added_record_dataset.name == None\n",
    "assert test_object_detection_added_record_dataset.description == None\n",
    "assert test_object_detection_added_record_dataset.class_map == test_object_detection_record_dataset.class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_mask = np.array([False]*test_object_detection_record_dataset.data.shape[0])\n",
    "test_object_detection_mask[1] = True\n",
    "test_object_detection_masked_record = test_object_detection_record_dataset.create_new_from_mask(test_object_detection_record_dataset, test_object_detection_mask)\n",
    "assert len(test_object_detection_masked_record) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_old_record_dataset_stats = test_object_detection_record_dataset.stats_dataset\n",
    "test_object_detection_record_dataset.records.list = test_object_detection_train_records\n",
    "test_object_detection_new_record_dataset_stats = test_object_detection_record_dataset.stats_dataset\n",
    "assert all(test_object_detection_new_record_dataset_stats != test_object_detection_old_record_dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_detection_regenerated_record_dataset = BboxRecordDataset.load_from_record_dataframe(test_object_detection_record_dataset.data, test_object_detection_class_map)\n",
    "assert len(test_object_detection_regenerated_record_dataset.records) == len(test_object_detection_record_dataset.records)\n",
    "test_object_detection_regenerated_record_dataset_no_class_map = BboxRecordDataset.load_from_record_dataframe(test_object_detection_record_dataset.data)\n",
    "assert sorted(test_object_detection_regenerated_record_dataset_no_class_map.class_map._id2class) == sorted(test_object_detection_class_map._id2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"dump_dir\", ignore_errors=True)\n",
    "os.mkdir(\"dump_dir\")\n",
    "test_object_detection_record_dataset.name = \"\"\n",
    "test_object_detection_record_dataset.save(\"dump_dir\")\n",
    "test_object_detection_record_dataset.save(\"dump_dir\")\n",
    "assert len(os.listdir(\"dump_dir\")) == 2\n",
    "assert os.path.isfile(\"dump_dir/dataset.json\")\n",
    "test_object_detection_loaded_record_dataset = BboxRecordDataset(\"dump_dir/dataset.json\")\n",
    "assert test_object_detection_record_dataset.data.sort_values(\"area\").shape == test_object_detection_loaded_record_dataset.data.sort_values(\"id\").shape\n",
    "shutil.rmtree(\"dump_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PrecisionRecallMetricsDescriptorObjectDetection(DatasetDescriptor):\n",
    "    def __init__(self, ious=None):\n",
    "        if ious is None:\n",
    "            self.ious = np.arange(0.5, 1, 0.05).round(2)\n",
    "        else:\n",
    "            self.ious = ious\n",
    "            \n",
    "    def calculate_description(self, obj):\n",
    "        return APObjectDetection(obj.base_data, self.ious).metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectDetectionResultsDataset(ResultsDataset):\n",
    "    \"\"\"Dashboard dataset for the results of and object detection system.\"\"\"\n",
    "    metric_data_ap = PrecisionRecallMetricsDescriptorObjectDetection()\n",
    "    df_parser = BboxRecordDataframeParser\n",
    "        \n",
    "    @classmethod\n",
    "    def init_from_preds_and_samples(cls, predictions, samples_plus_losses, padded_along_shortest=True, class_map=None, name=None, description=None):\n",
    "        \"\"\"The input_records are required because they are the only information source with the image stats(width, etc.) for the image on the disk.\"\"\"\n",
    "        data = []\n",
    "        for index, (prediction, sample_plus_loss) in enumerate(zip(predictions, samples_plus_losses)):\n",
    "            # TODO: At the moment only resize_and_pad or resize are handeled. Check if there are other edge cases that need to be included\n",
    "            # The correction requires that the sample_plus_loss has the scaled image sizes (not the padded ones or the original ones)\n",
    "            # correct the width and height to the values of the original image\n",
    "            prediction = prediction.pred.as_dict()[\"detection\"]\n",
    "            \n",
    "            losses = sample_plus_loss.losses\n",
    "            sample_plus_loss_dict = sample_plus_loss.as_dict()\n",
    "            # bbox correction\n",
    "            img = Image.open(str(sample_plus_loss.common.filepath))\n",
    "            width, height = img.size[0], img.size[1]\n",
    "            # use bool to int for padded_along_shortest and int(sample_plus_loss[\"width\"] < sample_plus_loss[\"height\"]) to avoid if branches\n",
    "            resize_factor = sample_plus_loss_dict[\"common\"][\"width\"]/width if width > height else sample_plus_loss_dict[\"common\"][\"height\"]/height\n",
    "            resized_x = resize_factor * width\n",
    "            resized_y = resize_factor * height\n",
    "            pad_x = sample_plus_loss_dict[\"common\"][\"width\"]-resized_x\n",
    "            pad_y = sample_plus_loss_dict[\"common\"][\"height\"]-resized_y\n",
    "            correct_x = lambda x: (x-pad_x/2)/resize_factor\n",
    "            correct_y = lambda y: (y-pad_y/2)/resize_factor\n",
    "            \n",
    "            if len(prediction[\"labels\"]) > 0:    \n",
    "                for label, bbox, score in zip(prediction[\"labels\"], prediction[\"bboxes\"], prediction[\"scores\"]):\n",
    "                    xmin, xmax, ymin, ymax = correct_x(bbox.xmin), correct_x(bbox.xmax), correct_y(bbox.ymin), correct_y(bbox.ymax)\n",
    "                    file_stats = sample_plus_loss.common.filepath.stat()\n",
    "                    bbox_width = xmax - xmin\n",
    "                    bbox_height = ymax - ymin\n",
    "                    area = bbox_width * bbox_height\n",
    "                    area_normalized = area / (width * height)\n",
    "                    bbox_ratio = bbox_width / bbox_height\n",
    "                    image_data = {\n",
    "                            \"id\": sample_plus_loss_dict[\"common\"][\"record_id\"], \"width\": width, \"height\": height, \"label\": label, \"area_square_root\": area**2, \"area_square_root_normalized\": area_normalized**2,\n",
    "                            \"score\": score, \"bbox_xmin\": xmin, \"bbox_xmax\": xmax, \"bbox_ymin\": ymin, \"bbox_ymax\": ymax, \"area\": area,  \n",
    "                            \"bbox_xmin_normalized\": xmin/width, \"bbox_xmax_normalized\": xmax/width, \"bbox_ymin_normalized\": ymin/height, \"bbox_ymax_normalized\": ymax/height,\n",
    "                            \"area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"bbox_ratio_normalized\": bbox_ratio*(height/width), \"record_index\": index, \n",
    "                            \"bbox_width\": bbox_width, \"bbox_height\": bbox_height, \"bbox_width_normalized\": bbox_width/width, \"bbox_height_normalized\": bbox_height/height,\n",
    "                            \"filepath\": str(sample_plus_loss.common.filepath), \"filename\": str(sample_plus_loss.common.filepath).split(\"/\")[-1], \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                            \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(prediction[\"bboxes\"]), \"is_prediction\": True,\n",
    "                        }\n",
    "                    for key, value in losses.items():\n",
    "                        image_data[key] = value\n",
    "                    data.append(image_data)\n",
    "            \n",
    "            if len(sample_plus_loss_dict[\"detection\"][\"labels\"]) > 0:\n",
    "                for label, bbox in zip(sample_plus_loss_dict[\"detection\"][\"labels\"], sample_plus_loss_dict[\"detection\"][\"bboxes\"]):\n",
    "                    xmin, xmax, ymin, ymax = correct_x(bbox.xmin), correct_x(bbox.xmax), correct_y(bbox.ymin), correct_y(bbox.ymax)\n",
    "                    file_stats = sample_plus_loss.common.filepath.stat()\n",
    "                    bbox_width = xmax - xmin\n",
    "                    bbox_height = ymax - ymin\n",
    "                    area = bbox_width * bbox_height\n",
    "                    area_normalized = area / (width * height)\n",
    "                    bbox_ratio = bbox_width / bbox_height \n",
    "                    image_data = {\n",
    "                            \"id\": sample_plus_loss_dict[\"common\"][\"record_id\"], \"width\": width, \"height\": height, \"label\": label,\n",
    "                            \"score\": 999, \"bbox_xmin\": xmin, \"bbox_xmax\": xmax, \"bbox_ymin\": ymin, \"bbox_ymax\": ymax, \"area\": area, \"area_square_root\": area**2, \"area_square_root_normalized\": area_normalized**2,\n",
    "                            \"area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"record_index\": index, \n",
    "                            \"bbox_xmin_normalized\": xmin/width, \"bbox_xmax_normalized\": xmax/width, \"bbox_ymin_normalized\": ymin/height, \"bbox_ymax_normalized\": ymax/height,\n",
    "                            \"bbox_width\": bbox_width, \"bbox_height\": bbox_height,  \"bbox_width_normalized\": bbox_width/width, \"bbox_height_normalized\": bbox_height/height, \n",
    "                            \"filepath\": str(sample_plus_loss.common.filepath), \"filename\": str(sample_plus_loss.common.filepath).split(\"/\")[-1], \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                            \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(prediction[\"bboxes\"]), \"is_prediction\": False,\n",
    "                        }\n",
    "                    for key, value in losses.items():\n",
    "                        image_data[key] = value\n",
    "                    data.append(image_data)\n",
    "\n",
    "        data = pd.DataFrame(data)\n",
    "        \n",
    "        data[\"label_num\"] = data[\"label\"]\n",
    "        if class_map is not None:\n",
    "            data[\"label_num\"] = data[\"label\"].apply(class_map.get_by_name)\n",
    "\n",
    "        if not any(data[\"is_prediction\"] == True):\n",
    "            raise ValueError(\"No predictions found.\")\n",
    "        \n",
    "        return cls(data, name, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_odrd = ObjectDetectionResultsDataset.load(\"test_data/object_detection_result_ds.dat\")\n",
    "test_object_detection_preds = pickle.load(open(\"test_data/object_detection_preds.pkl\", \"rb\"))\n",
    "test_object_detection_samples = pickle.load(open(\"test_data/object_detection_samples.pkl\", \"rb\"))\n",
    "\n",
    "# make the saved samples indipendent of the saved enviroment\n",
    "for sample in test_object_detection_samples:\n",
    "    sample.common.filepath = Path(str(test_object_detection_data_dir).split(\".icevision\")[0] + \".icevision\" + str(sample.common.filepath).split(\".icevision\")[-1])\n",
    "\n",
    "test_odrd_from_samples = ObjectDetectionResultsDataset.init_from_preds_and_samples(test_object_detection_preds, test_object_detection_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InstanceSegmentationRecordDataframeParser(RecordDataframeParser):\n",
    "    \"\"\"Extends the RecordDataframeParser for instance segmentation\"\"\"\n",
    "    def __init__(self, record_dataframe, class_map):\n",
    "        super().__init__(InstanceSegmentationRecord())\n",
    "        self.record_dataframe = record_dataframe\n",
    "        self.class_map = class_map\n",
    "\n",
    "    def parse_fields(self, o, record, is_new):\n",
    "        super().parse_fields(o, record, is_new)\n",
    "        bboxes = []\n",
    "        masks  = []\n",
    "        for annot in o.iterrows():\n",
    "            bboxes.append(BBox(annot[1][\"bbox_xmin\"], annot[1][\"bbox_ymin\"], annot[1][\"bbox_xmax\"], annot[1][\"bbox_ymax\"]))\n",
    "            masks.append(EncodedRLEs([string_to_erles(annot[1][\"erles_corrected\"])]))\n",
    "        record.detection.add_bboxes(bboxes)\n",
    "        record.detection.add_masks(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataDescriptorInstanceSegmentation(DatasetDescriptor):\n",
    "    \"\"\"Dashboard dataset for object detection\"\"\"\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Aggregates stats from a list of records and returns a pandas dataframe with the aggregated stats. The creation time is not necessarily the real creation time. \n",
    "        This depends on the OS, for more information see: https://docs.python.org/3/library/os.html#os.stat_result.\"\"\"\n",
    "        data = []\n",
    "        summe = 0\n",
    "        for index,record in enumerate(obj.records):\n",
    "            record_commons, record_detections = record.as_dict()[\"common\"], record.as_dict()[\"detection\"]\n",
    "            \n",
    "            if isinstance(record_detections[\"masks\"][0], EncodedRLEs):\n",
    "                masks_to_iterate_over = [entry.erles[0] for entry in record_detections[\"masks\"]]\n",
    "            else:\n",
    "                masks_to_iterate_over = record_detections[\"masks\"][0].to_erles(None,None).erles\n",
    "\n",
    "            for label, bbox, mask in zip(record_detections[\"labels\"], record_detections[\"bboxes\"], masks_to_iterate_over):\n",
    "                mask_array = mask_utils.decode([mask])\n",
    "                file_stats = record.filepath.stat()\n",
    "                area = bbox.width*bbox.height\n",
    "                area_normalized = area / (record.width * record.height)\n",
    "                bbox_ratio = bbox.width / bbox.height\n",
    "                \n",
    "                data.append(\n",
    "                    {\n",
    "                        \"id\": record_commons[\"record_id\"], \"width\": record.width, \"height\": record.height, \"label\": label, \"bbox_area_square_root\": bbox.area**0.5, \"bbox_area_square_root_normalized\": area_normalized**0.5,\n",
    "                        \"bbox_xmin\": bbox.xmin, \"bbox_xmax\": bbox.xmin+bbox.width, \"bbox_ymin\": bbox.ymin, \"bbox_ymax\": bbox.ymin+bbox.height, \n",
    "                        \"bbox_xmin_normalized\": bbox.xmin/record.width, \"bbox_xmax_normalized\": (bbox.xmin+bbox.width)/record.width, \"bbox_ymin_normalized\": bbox.ymin/record.height,\n",
    "                        \"bbox_ymax_normalized\": (bbox.ymin+bbox.height)/record.height, \"bbox_area\": area, \"bbox_area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"bbox_ratio_normalized\": bbox_ratio*(record.height/record.width),\n",
    "                        \"record_index\": index, \"bbox_width\": bbox.width, \"bbox_height\": bbox.height, \"bbox_width_normalized\": bbox.width/record.width, \"bbox_height_normalized\": bbox.height/record.height, \n",
    "                        \"filepath\": str(record.filepath), \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                        \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(record_detections[\"bboxes\"]),\n",
    "                        \"erles_corrected\": erles_to_string(mask), \"erles\": erles_to_string(mask), \"mask_area\": mask_array.sum(), \"mask_area_normalized\": mask_array.sum()/mask_array.size, \"mask_area_normalized_by_bbox_area\": mask_array.sum()/area,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        data = pd.DataFrame(data)\n",
    "        data[\"label_num\"] = data[\"label\"]\n",
    "        if obj.class_map is not None:\n",
    "            data[\"label_num\"] = data[\"label\"].apply(obj.class_map.get_by_name)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StatsDescriptorInstanceSegmentation(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        stats_dict = {}\n",
    "        stats_dict[\"no_imgs\"] = [obj.data[\"filepath\"].nunique()]\n",
    "        stats_dict[\"no_classes\"] = [obj.data[\"label\"].nunique()]\n",
    "        stats_dict[\"classes\"] = [list(obj.data[\"label\"].unique())]\n",
    "        stats_dict[\"mask_area_min\"] = [obj.data[\"mask_area\"].min()]\n",
    "        stats_dict[\"mask_area_max\"] = [obj.data[\"mask_area\"].max()]\n",
    "        stats_dict[\"num_annotations_min\"] = [obj.data[\"num_annotations\"].min()]\n",
    "        stats_dict[\"num_annotations_max\"] = [obj.data[\"num_annotations\"].max()]\n",
    "        stats_dict[\"name\"] = [obj._name]\n",
    "        stats_dict[\"description\"] = [obj._description]\n",
    "        return pd.DataFrame(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageStatsDescriptorInstanceSegmentation(ImageStatsDescriptorBbox):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ClassStatsDescriptorInstanceSegmentation(ClassStatsDescriptorBbox):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Creates a dataframe containing stats about the object classes.\"\"\"\n",
    "        stats_dict = {}\n",
    "        label_group = obj.data.groupby(\"label\")\n",
    "        for label, group in label_group:\n",
    "            label_stats = {}\n",
    "            label_stats[\"imgs\"] = group[\"filepath\"].nunique()\n",
    "            label_stats[\"objects\"] = group.shape[0]\n",
    "            label_stats[\"avg_objects_per_img\"] = label_stats[\"objects\"]/label_stats[\"imgs\"]\n",
    "            label_stats[\"frac_of_labels\"] = round(label_stats[\"objects\"]/obj.data.shape[0], 2)\n",
    "            stats_dict[label] = label_stats\n",
    "        df = pd.DataFrame(stats_dict).T\n",
    "        df = df.rename_axis('Class').reset_index()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GalleryStatsDescriptorInstanceSegmentation(DatasetDescriptor):\n",
    "    def calculate_description(self, obj):\n",
    "        \"\"\"Creates a dataframe containing the data for a gallery.\"\"\"\n",
    "        df = obj.data[[\"id\", \"bbox_area\", \"num_annotations\", \"label\", \"bbox_ratio\", \"bbox_width\", \"bbox_height\", \"mask_area\", \"mask_area_normalized\", \"width\", \"height\"]].drop_duplicates().reset_index(drop=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InstanceSegmentationRecordDataset(RecordDataset):\n",
    "    data = DataDescriptorInstanceSegmentation()\n",
    "    gallery_data = GalleryStatsDescriptorInstanceSegmentation()\n",
    "    stats_dataset = StatsDescriptorInstanceSegmentation()\n",
    "    stats_image = ImageStatsDescriptorInstanceSegmentation()\n",
    "    stats_class = ClassStatsDescriptorInstanceSegmentation()\n",
    "    stats = StatsDescriptorInstanceSegmentation()\n",
    "    \n",
    "    def __init__(self, records: Union[List[BaseRecord], ObservableList, str], class_map=None, name=None, description=None):\n",
    "        super().__init__(records, class_map, name, description)\n",
    "        self.record_index_image_id_map = {str(record.filepath): index for index, record in enumerate(self.records)}\n",
    "        self.data = None\n",
    "        self.gallery_data = None\n",
    "        self.stats_dataset = None\n",
    "        self.stats_image = None\n",
    "        self.stats_class = None\n",
    "        self.stats = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_df_to_records(record_data_df, class_map):\n",
    "        return InstanceSegmentationRecordDataframeParser(record_data_df, class_map).parse(SingleSplitSplitter())[0]\n",
    "    \n",
    "    def get_image_by_image_id(self, image_id, width, height):\n",
    "        index = self.record_index_image_id_map[image_id]\n",
    "        return draw_record_with_bokeh(self[index], display_bbox=True, display_mask=True, class_map=self.class_map, width=None, height=height, return_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_record_dataset = InstanceSegmentationRecordDataset(test_instance_segmentation_train_records, test_instance_segmentation_train_records[0].detection.class_map)\n",
    "assert isinstance(test_instance_segmentation_record_dataset.data, pd.DataFrame)\n",
    "assert isinstance(test_instance_segmentation_record_dataset.stats_dataset, pd.DataFrame)\n",
    "assert isinstance(test_instance_segmentation_record_dataset.stats_class, pd.DataFrame)\n",
    "assert isinstance(test_instance_segmentation_record_dataset.stats_image, pd.DataFrame)\n",
    "assert isinstance(test_instance_segmentation_record_dataset.stats, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_mask = np.array([False]*test_instance_segmentation_record_dataset.data.shape[0])\n",
    "test_instance_segmentation_mask[1] = True\n",
    "test_instance_segmentation_masked_test_record = test_instance_segmentation_record_dataset.create_new_from_mask(test_instance_segmentation_record_dataset, test_instance_segmentation_mask)\n",
    "assert len(test_instance_segmentation_masked_test_record) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_old_record_dataset_stats = test_instance_segmentation_record_dataset.stats_dataset\n",
    "test_instance_segmentation_record_dataset.records.list = test_instance_segmentation_train_records\n",
    "test_new_record_dataset_stats = test_instance_segmentation_record_dataset.stats_dataset\n",
    "assert all(test_old_record_dataset_stats != test_new_record_dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_regenerated_record_dataset = InstanceSegmentationRecordDataset.load_from_record_dataframe(test_instance_segmentation_record_dataset.data, test_instance_segmentation_class_map)\n",
    "assert len(test_instance_segmentation_regenerated_record_dataset.records) == len(test_instance_segmentation_record_dataset.records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"dump_dir\", ignore_errors=True)\n",
    "os.mkdir(\"dump_dir\")\n",
    "test_instance_segmentation_record_dataset.name = \"dataset_instance_segmentation\"\n",
    "test_instance_segmentation_record_dataset.save(\"dump_dir\")\n",
    "test_instance_segmentation_record_dataset.save(\"dump_dir\")\n",
    "assert len(os.listdir(\"dump_dir\")) == 2\n",
    "assert os.path.isfile(\"dump_dir/dataset_instance_segmentation.json\")\n",
    "test_instance_segmentation_loaded_record_dataset = InstanceSegmentationRecordDataset(\"dump_dir/dataset_instance_segmentation.json\")\n",
    "assert test_instance_segmentation_record_dataset.data.sort_values(\"id\").shape == test_instance_segmentation_loaded_record_dataset.data.sort_values(\"id\").shape\n",
    "shutil.rmtree(\"dump_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PrecisionRecallMetricsDescriptorInstanceSegmentation(DatasetDescriptor):\n",
    "    def __init__(self, ious=None):\n",
    "        if ious is None:\n",
    "            self.ious = np.arange(0.5, 1, 0.05).round(2)\n",
    "        else:\n",
    "            self.ious = ious\n",
    "            \n",
    "    def calculate_description(self, obj):\n",
    "        return APInstanceSegmentation(obj.base_data, self.ious).metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InstanceSegmentationResultsDataset(ResultsDataset):\n",
    "    \"\"\"Dashboard dataset for the results of and object detection system.\"\"\"\n",
    "    metric_data_ap = PrecisionRecallMetricsDescriptorInstanceSegmentation()\n",
    "    df_parser = InstanceSegmentationRecordDataframeParser\n",
    "\n",
    "    @staticmethod\n",
    "    def get_masks_to_iterate_over(prediction):\n",
    "        if len(prediction[\"masks\"]) > 0:\n",
    "            if isinstance(prediction[\"masks\"][0], EncodedRLEs):\n",
    "                masks_to_iterate_over = [entry.erles[0] for entry in prediction[\"masks\"]]\n",
    "            elif isinstance(prediction[\"masks\"][0], MaskArray):\n",
    "                masks_to_iterate_over = [entry.to_erles(None, None).erles[0] for entry in prediction[\"masks\"]]\n",
    "            else:\n",
    "                masks_to_iterate_over = prediction[\"masks\"][0].to_erles(None,None).erles\n",
    "        else:\n",
    "            masks_to_iterate_over = prediction[\"mask_array\"].to_erles(None,None).erles\n",
    "        return masks_to_iterate_over\n",
    "        \n",
    "    @classmethod\n",
    "    def init_from_preds_and_samples(cls, predictions, samples_plus_losses, padded_along_shortest=True, class_map=None, name=None, description=None):\n",
    "        \"\"\"The input_records are required because they are the only information source with the image stats(width, etc.) for the image on the disk.\"\"\"\n",
    "        data = []\n",
    "        for index, (prediction, sample_plus_loss) in enumerate(zip(predictions, samples_plus_losses)):\n",
    "            # TODO: At the moment only resize_and_pad or resize are handeled. Check if there are other edge cases that need to be included\n",
    "            # The correction requires that the sample_plus_loss has the scaled image sizes (not the padded ones or the original ones)\n",
    "            # correct the width and height to the values of the original image\n",
    "            prediction = prediction.pred.as_dict()[\"detection\"]\n",
    "            losses = sample_plus_loss.losses\n",
    "            sample_plus_loss_dict = sample_plus_loss.as_dict()\n",
    "            # bbox correction\n",
    "            img = Image.open(sample_plus_loss.common.filepath)\n",
    "            width, height = img.size[0], img.size[1]\n",
    "            # use bool to int for padded_along_shortest and int(sample_plus_loss[\"width\"] < sample_plus_loss[\"height\"]) to avoid if branches\n",
    "            resize_factor = sample_plus_loss_dict[\"common\"][\"width\"]/width if width > height else sample_plus_loss_dict[\"common\"][\"height\"]/height\n",
    "            resized_x = resize_factor * width\n",
    "            resized_y = resize_factor * height\n",
    "            pad_x = sample_plus_loss_dict[\"common\"][\"width\"]-resized_x\n",
    "            pad_y = sample_plus_loss_dict[\"common\"][\"height\"]-resized_y\n",
    "            correct_x = lambda x: (x-pad_x/2)/resize_factor\n",
    "            correct_y = lambda y: (y-pad_y/2)/resize_factor\n",
    "\n",
    "            if len(prediction[\"labels\"]) > 0:                \n",
    "                masks_to_iterate_over = cls.get_masks_to_iterate_over(prediction)\n",
    "                \n",
    "                for label, bbox, score, mask in zip(prediction[\"labels\"], prediction[\"bboxes\"], prediction[\"scores\"], masks_to_iterate_over):\n",
    "                    mask_array = mask_utils.decode([mask])\n",
    "                    xmin, xmax, ymin, ymax = correct_x(bbox.xmin), correct_x(bbox.xmax), correct_y(bbox.ymin), correct_y(bbox.ymax)\n",
    "                    file_stats = sample_plus_loss.common.filepath.stat()\n",
    "                    bbox_width = xmax - xmin\n",
    "                    bbox_height = ymax - ymin\n",
    "                    area = bbox_width * bbox_height\n",
    "                    area_normalized = area / (width * height)\n",
    "                    bbox_ratio = bbox_width / bbox_height\n",
    "                    # correct mask\n",
    "                    corrected_mask = correct_mask(mask_array, pad_x, pad_y, width, height)\n",
    "                    corrected_mask = corrected_mask.to_erles(None, None).erles[0]\n",
    "                    \n",
    "                    image_data = {\n",
    "                        \"id\": sample_plus_loss_dict[\"common\"][\"record_id\"], \"width\": width, \"height\": height, \"label\": label, \"bbox_area_square_root\": area**2, \"bbox_area_square_root_normalized\": area_normalized**2,\n",
    "                        \"score\": score, \"bbox_xmin\": xmin, \"bbox_xmax\": xmax, \"bbox_ymin\": ymin, \"bbox_ymax\": ymax, \"bbox_area\": area,  \n",
    "                        \"bbox_xmin_normalized\": xmin/width, \"bbox_xmax_normalized\": xmax/width, \"bbox_ymin_normalized\": ymin/height, \"bbox_ymax_normalized\": ymax/height,\n",
    "                        \"bbox_area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"bbox_ratio_normalized\": bbox_ratio*(height/width), \"record_index\": index, \n",
    "                        \"bbox_width\": bbox_width, \"bbox_height\": bbox_height, \"bbox_width_normalized\": bbox_width/width, \"bbox_height_normalized\": bbox_height/height,\n",
    "                        \"erles_corrected\": erles_to_string(corrected_mask), \"erles\": erles_to_string(mask), \"mask_area\": mask_array.sum(), \"mask_area_normalized\": mask_array.sum()/mask_array.size, \"mask_area_normalized_by_bbox_area\": mask_array.sum()/area,\n",
    "                        \"filepath\": str(sample_plus_loss.common.filepath), \"filename\": str(sample_plus_loss.common.filepath).split(\"/\")[-1], \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                        \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(prediction[\"bboxes\"]), \"is_prediction\": True,\n",
    "                    }\n",
    "                    for key, value in losses.items():\n",
    "                        image_data[key] = value\n",
    "                    data.append(image_data)\n",
    "            \n",
    "            if len(sample_plus_loss_dict[\"detection\"][\"labels\"]) > 0:\n",
    "                masks_to_iterate_over = cls.get_masks_to_iterate_over(sample_plus_loss_dict[\"detection\"])\n",
    "                for label, bbox, mask in zip(sample_plus_loss_dict[\"detection\"][\"labels\"], sample_plus_loss_dict[\"detection\"][\"bboxes\"], masks_to_iterate_over):\n",
    "                    mask_array = mask_utils.decode([mask])\n",
    "                    xmin, xmax, ymin, ymax = correct_x(bbox.xmin), correct_x(bbox.xmax), correct_y(bbox.ymin), correct_y(bbox.ymax)\n",
    "                    file_stats = sample_plus_loss.common.filepath.stat()\n",
    "                    bbox_width = xmax - xmin\n",
    "                    bbox_height = ymax - ymin\n",
    "                    area = bbox_width * bbox_height\n",
    "                    area_normalized = area / (width * height)\n",
    "                    bbox_ratio = bbox_width / bbox_height \n",
    "                    # correct mask\n",
    "                    decorrected_mask = decorrect_mask(mask_array, int(pad_x/2), int(pad_y/2), width, height)\n",
    "                    decorrected_mask = decorrected_mask.to_erles(None, None).erles[0]\n",
    "                    \n",
    "                    # Below the erles_corrected is set to the mask and not the mask_corrected because atm icevision does not transform the masks in the record. Only in the output of the data loader is transformed  \n",
    "                    image_data = {\n",
    "                        \"id\": sample_plus_loss_dict[\"common\"][\"record_id\"], \"width\": width, \"height\": height, \"label\": label,\n",
    "                        \"score\": 999, \"bbox_xmin\": xmin, \"bbox_xmax\": xmax, \"bbox_ymin\": ymin, \"bbox_ymax\": ymax, \"bbox_area\": area, \"bbox_area_square_root\": area**2, \"bbox_area_square_root_normalized\": area_normalized**2,\n",
    "                        \"bbox_area_normalized\": area_normalized, \"bbox_ratio\": bbox_ratio, \"record_index\": index, \n",
    "                        \"bbox_xmin_normalized\": xmin/width, \"bbox_xmax_normalized\": xmax/width, \"bbox_ymin_normalized\": ymin/height, \"bbox_ymax_normalized\": ymax/height,\n",
    "                        \"bbox_width\": bbox_width, \"bbox_height\": bbox_height,  \"bbox_width_normalized\": bbox_width/width, \"bbox_height_normalized\": bbox_height/height,\n",
    "                        \"erles_corrected\": erles_to_string(mask), \"erles\": erles_to_string(decorrected_mask), \"mask_area\": mask_array.sum(), \"mask_area_normalized\": mask_array.sum()/mask_array.size, \"mask_area_normalized_by_bbox_area\": mask_array.sum()/area,\n",
    "                        \"filepath\": str(sample_plus_loss.common.filepath), \"filename\": str(sample_plus_loss.common.filepath).split(\"/\")[-1], \"creation_date\": datetime.datetime.fromtimestamp(file_stats.st_ctime), \n",
    "                        \"modification_date\": datetime.datetime.fromtimestamp(file_stats.st_mtime), \"num_annotations\": len(prediction[\"bboxes\"]), \"is_prediction\": False,\n",
    "                    }\n",
    "                    for key, value in losses.items():\n",
    "                        image_data[key] = value\n",
    "                    data.append(image_data)\n",
    "\n",
    "        data = pd.DataFrame(data)\n",
    "        data[\"label_num\"] = data[\"label\"]\n",
    "        if class_map is not None:\n",
    "            data[\"label_num\"] = data[\"label\"].apply(class_map.get_by_name)\n",
    "\n",
    "        if not any(data[\"is_prediction\"] == True):\n",
    "            raise ValueError(\"No predictions found.\")\n",
    "        \n",
    "        return cls(data, name, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance_segmentation_odrd = InstanceSegmentationResultsDataset.load(\"test_data/instance_segmentation_result_ds_valid.dat\")\n",
    "test_instance_segmentation_preds = pickle.load(open(\"test_data/instance_segmentation_preds.pkl\", \"rb\"))\n",
    "test_instance_segmentation_samples = pickle.load(open(\"test_data/instance_segmentation_samples.pkl\", \"rb\"))\n",
    "\n",
    "# make the saved samples indipendent of the saved enviroment\n",
    "for sample in test_instance_segmentation_samples:\n",
    "    for _ in sample.components:\n",
    "        if isinstance(_, FilepathRecordComponent):\n",
    "            _.set_filepath(Path(str(test_instance_segmentation_data_path).split(\".icevision\")[0] + \".icevision\" + str(sample.common.filepath).split(\".icevision\")[-1]))\n",
    "    sample.detection.masks[0].filepath = Path(str(test_instance_segmentation_data_path).split(\".icevision\")[0] + \".icevision\" + str(sample.common.filepath).split(\".icevision\")[-1])\n",
    "        \n",
    "test_odrd_from_samples = InstanceSegmentationResultsDataset.init_from_preds_and_samples(test_instance_segmentation_preds, test_instance_segmentation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
